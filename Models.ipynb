{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Bidirectional, BatchNormalization,Dropout,SimpleRNN\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as plt\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"vectorized_input_3d_refined.npy\",allow_pickle=True)\n",
    "labels = np.load(\"vectorized_output_3d_refined.npy\",allow_pickle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_142 (LSTM)             (None, 721, 32)           17280     \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 721, 32)           128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " lstm_143 (LSTM)             (None, 721, 32)           8320      \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 721, 6)            198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25926 (101.27 KB)\n",
      "Trainable params: 25862 (101.02 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[397], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[39m=\u001b[39mAdam(learning_rate \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m)\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,optimizer\u001b[39m=\u001b[39moptimizer , metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    903\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    906\u001b[0m         args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    907\u001b[0m     )\n\u001b[0;32m    908\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m   bound_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\n\u001b[0;32m    910\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds\n\u001b[0;32m    911\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m ()\n\u001b[0;32m    131\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m--> 132\u001b[0m function \u001b[39m=\u001b[39m trace_function(\n\u001b[0;32m    133\u001b[0m     args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, tracing_options\u001b[39m=\u001b[39;49mtracing_options\n\u001b[0;32m    134\u001b[0m )\n\u001b[0;32m    136\u001b[0m \u001b[39m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[0;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[0;32m    180\u001b[0m   )\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[0;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[0;32m    285\u001b[0m )\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39mattributes \u001b[39mand\u001b[39;00m tracing_options\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[39m.\u001b[39mDISABLE_ACD, \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    311\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    312\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mpython_function,\n\u001b[0;32m    313\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49margs,\n\u001b[0;32m    314\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49mkwargs,\n\u001b[0;32m    315\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    316\u001b[0m     func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    317\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m disable_acd,\n\u001b[0;32m    318\u001b[0m     arg_names\u001b[39m=\u001b[39;49mfunction_type_utils\u001b[39m.\u001b[39;49mto_arg_names(function_type),\n\u001b[0;32m    319\u001b[0m     create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    320\u001b[0m )\n\u001b[0;32m    322\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 598\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    599\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m     42\u001b[0m       original_func,\n\u001b[0;32m     43\u001b[0m       args,\n\u001b[0;32m     44\u001b[0m       kwargs,\n\u001b[0;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     49\u001b[0m       ))\n\u001b[0;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\WENYEZ~1\\AppData\\Local\\Temp\\__autograph_generated_file839_wljq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1380\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1381\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     )\n\u001b[0;32m   1383\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1384\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1385\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1386\u001b[0m     outputs,\n\u001b[0;32m   1387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1388\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1389\u001b[0m )\n\u001b[0;32m   1390\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1677\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1679\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1680\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1681\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3269\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3270\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 3271\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4067\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4068\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 4069\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1373\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1374\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1154\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1153\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m-> 1154\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m   1155\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    523\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[39m      None\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_gradients(loss, var_list, tape)\n\u001b[0;32m    544\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:276\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(var_list):\n\u001b[0;32m    274\u001b[0m             var_list \u001b[39m=\u001b[39m var_list()\n\u001b[1;32m--> 276\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list)\n\u001b[0;32m    277\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1060\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1061\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1062\u001b[0m           output_gradients))\n\u001b[0;32m   1063\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1064\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1066\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1067\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1068\u001b[0m     flat_targets,\n\u001b[0;32m   1069\u001b[0m     flat_sources,\n\u001b[0;32m   1070\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1071\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1072\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1074\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1075\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    146\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    150\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:369\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39m# We compute the gradient for the sub-graph between trainable ys and xs\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m# with non-None incoming gradients. We later pad the None's to the list of\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m# outputs.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m ys, xs, non_none_grads \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[(y, x, grad) \u001b[39mfor\u001b[39;00m (y, x, grad) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    367\u001b[0m     body_graph\u001b[39m.\u001b[39moutputs, body_graph\u001b[39m.\u001b[39minputs, grads) \u001b[39mif\u001b[39;00m grad \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m])\n\u001b[1;32m--> 369\u001b[0m body_grad_graph, args \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    370\u001b[0m     ys, xs, non_none_grads, cond_graph, body_graph,\n\u001b[0;32m    371\u001b[0m     util\u001b[39m.\u001b[39;49munique_grad_fn_name(body_graph\u001b[39m.\u001b[39;49mname), op, maximum_iterations)\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m body_grad_graph\u001b[39m.\u001b[39mwhile_op_needs_rewrite:\n\u001b[0;32m    374\u001b[0m   \u001b[39m# Modify 'op' to output the intermediate accumulators needed by the grad\u001b[39;00m\n\u001b[0;32m    375\u001b[0m   \u001b[39m# function.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m   \u001b[39m# NOTE(skyewm): if there are any active sessions, this modification to `op`\u001b[39;00m\n\u001b[0;32m    377\u001b[0m   \u001b[39m# may make them unrunnable!\u001b[39;00m\n\u001b[0;32m    379\u001b[0m   cond_graph\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_rewritten\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:665\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[1;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations)\u001b[0m\n\u001b[0;32m    662\u001b[0m args \u001b[39m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(grads)\n\u001b[0;32m    663\u001b[0m \u001b[39m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[39m# `external_captures`.\u001b[39;00m\n\u001b[1;32m--> 665\u001b[0m grad_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    666\u001b[0m     name,\n\u001b[0;32m    667\u001b[0m     \u001b[39mlambda\u001b[39;49;00m \u001b[39m*\u001b[39;49margs: _grad_fn(ys, xs, args, body_graph),\n\u001b[0;32m    668\u001b[0m     args, {},\n\u001b[0;32m    669\u001b[0m     func_graph\u001b[39m=\u001b[39;49m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[0;32m    670\u001b[0m                                        maximum_iterations, while_op,\n\u001b[0;32m    671\u001b[0m                                        body_graph_inputs, body_graph_outputs))\n\u001b[0;32m    673\u001b[0m \u001b[39m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[39m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[39m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[39mfor\u001b[39;00m external_capture, internal_capture \u001b[39min\u001b[39;00m grad_func_graph\u001b[39m.\u001b[39mcaptures:\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:667\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    662\u001b[0m args \u001b[39m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(grads)\n\u001b[0;32m    663\u001b[0m \u001b[39m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[39m# `external_captures`.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m grad_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    666\u001b[0m     name,\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs: _grad_fn(ys, xs, args, body_graph),\n\u001b[0;32m    668\u001b[0m     args, {},\n\u001b[0;32m    669\u001b[0m     func_graph\u001b[39m=\u001b[39m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[0;32m    670\u001b[0m                                        maximum_iterations, while_op,\n\u001b[0;32m    671\u001b[0m                                        body_graph_inputs, body_graph_outputs))\n\u001b[0;32m    673\u001b[0m \u001b[39m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[39m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[39m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[39mfor\u001b[39;00m external_capture, internal_capture \u001b[39min\u001b[39;00m grad_func_graph\u001b[39m.\u001b[39mcaptures:\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:722\u001b[0m, in \u001b[0;36m_grad_fn\u001b[1;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[0;32m    715\u001b[0m grad_ys \u001b[39m=\u001b[39m args[\u001b[39m3\u001b[39m:]\n\u001b[0;32m    717\u001b[0m \u001b[39m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[39m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[39m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[39m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[39m# TODO(srbs): Mark GradientsHelper as public?\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m grad_outs \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[0;32m    723\u001b[0m     ys, xs, grad_ys\u001b[39m=\u001b[39;49mgrad_ys, src_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    724\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzero\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    726\u001b[0m \u001b[39m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# is a tf.StopGradient in the loop body.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grad_outs)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:733\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    729\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    730\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    731\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    734\u001b[0m                              \u001b[39mlambda\u001b[39;49;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    735\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    739\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:365\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    362\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[1;32m--> 365\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:734\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    729\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    730\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    731\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 734\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    735\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    739\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1379\u001b[0m, in \u001b[0;36m_AddGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1377\u001b[0m gx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39min\u001b[39;00m skip_input_indices \u001b[39melse\u001b[39;00m grad\n\u001b[0;32m   1378\u001b[0m gy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m skip_input_indices \u001b[39melse\u001b[39;00m grad\n\u001b[1;32m-> 1379\u001b[0m \u001b[39mreturn\u001b[39;00m _ReduceGradientArgs(x, y, gx, gy)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:142\u001b[0m, in \u001b[0;36m_ReduceGradientArgs\u001b[1;34m(x, y, gx, gy)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reduces gradients of both arguments of a broadcasting binary op.\"\"\"\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m gx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m gy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m   bx, by \u001b[39m=\u001b[39m SmartBroadcastGradientArgs(x, y)\n\u001b[0;32m    143\u001b[0m   gx \u001b[39m=\u001b[39m _ReduceGradientArg(gx, bx)\n\u001b[0;32m    144\u001b[0m   gy \u001b[39m=\u001b[39m _ReduceGradientArg(gy, by)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:87\u001b[0m, in \u001b[0;36mSmartBroadcastGradientArgs\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     83\u001b[0m   x_axes, y_axes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39mif\u001b[39;00m x_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m y_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m   \u001b[39m# NOTE: In graph mode, this is never exercised for statically known shapes.\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m   x_axes, y_axes \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mbroadcast_gradient_args(x_shape, y_shape)\n\u001b[0;32m     88\u001b[0m   x_must_reduce \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     89\u001b[0m   y_must_reduce \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:796\u001b[0m, in \u001b[0;36mbroadcast_gradient_args\u001b[1;34m(s0, s1, name)\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    797\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mBroadcastGradientArgs\u001b[39;49m\u001b[39m\"\u001b[39;49m, s0\u001b[39m=\u001b[39;49ms0, s1\u001b[39m=\u001b[39;49ms1, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    798\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    799\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    792\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    794\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    795\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    797\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    798\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    800\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    804\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1013\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[39mif\u001b[39;00m (op_type \u001b[39min\u001b[39;00m optimized_reduction_ops \u001b[39mand\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     \u001b[39mnot\u001b[39;00m util\u001b[39m.\u001b[39moutput_all_intermediates() \u001b[39mand\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39mall\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1001\u001b[0m     \u001b[39mnot\u001b[39;00m util\u001b[39m.\u001b[39mgraph_wrapped_for_higher_order_tape_gradients(\n\u001b[0;32m   1002\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph)):\n\u001b[0;32m   1003\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_move_op_to_forward_graph(\n\u001b[0;32m   1004\u001b[0m       op_type,\n\u001b[0;32m   1005\u001b[0m       inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1010\u001b[0m       op_def\u001b[39m=\u001b[39mop_def,\n\u001b[0;32m   1011\u001b[0m       compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m-> 1013\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(_WhileBodyGradFuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(\n\u001b[0;32m   1014\u001b[0m     op_type,\n\u001b[0;32m   1015\u001b[0m     inputs,\n\u001b[0;32m   1016\u001b[0m     dtypes\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   1017\u001b[0m     input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   1018\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1019\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1020\u001b[0m     op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   1021\u001b[0m     compute_device\u001b[39m=\u001b[39;49mcompute_device)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:668\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    666\u001b[0m   \u001b[39mif\u001b[39;00m ctxt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ctxt, \u001b[39m\"\u001b[39m\u001b[39mAddValue\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    667\u001b[0m     inp \u001b[39m=\u001b[39m ctxt\u001b[39m.\u001b[39mAddValue(inp)\n\u001b[1;32m--> 668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m    670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:675\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcapture\u001b[39m(\u001b[39mself\u001b[39m, tensor, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 675\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_captures\u001b[39m.\u001b[39;49mcapture_by_value(\u001b[39mself\u001b[39;49m, tensor, name)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\core\\function\\capture\\capture_container.py:154\u001b[0m, in \u001b[0;36mFunctionCaptures.capture_by_value\u001b[1;34m(self, graph, tensor, name)\u001b[0m\n\u001b[0;32m    151\u001b[0m     name \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mname\n\u001b[0;32m    152\u001b[0m   \u001b[39m# cond/while graphs override _capture_helper() so cannot call\u001b[39;00m\n\u001b[0;32m    153\u001b[0m   \u001b[39m# self.create_placeholder_helper() here directly.\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m   \u001b[39mreturn\u001b[39;00m graph\u001b[39m.\u001b[39;49m_capture_helper(tensor, name)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1186\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._capture_helper\u001b[1;34m(self, tensor, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[39m# Push the intermediate tensor to the tensor list. This captures\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[39m# `tensor_list`.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m-> 1186\u001b[0m   accumulator \u001b[39m=\u001b[39m list_ops\u001b[39m.\u001b[39;49mtensor_list_push_back(tensor_list, tensor)\n\u001b[0;32m   1187\u001b[0m \u001b[39m# Add the modified tensor list to the list of outputs. This output will be\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# all the accumulated values.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mappend(accumulator)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_list_ops.py:787\u001b[0m, in \u001b[0;36mtensor_list_push_back\u001b[1;34m(input_handle, tensor, name)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    788\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mTensorListPushBack\u001b[39;49m\u001b[39m\"\u001b[39;49m, input_handle\u001b[39m=\u001b[39;49minput_handle, tensor\u001b[39m=\u001b[39;49mtensor,\n\u001b[0;32m    789\u001b[0m                             name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    790\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    791\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    792\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    794\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    795\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    797\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    798\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    800\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    804\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   2649\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   2650\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   2651\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 2652\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   2653\u001b[0m       node_def,\n\u001b[0;32m   2654\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2655\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   2656\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   2657\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   2658\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   2659\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   2660\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   2661\u001b[0m   )\n\u001b[0;32m   2662\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   2663\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1160\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1159\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1161\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m   1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Wenye Zhou\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1017\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1013\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1014\u001b[0m                                          serialized)\n\u001b[0;32m   1016\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1017\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1018\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1019\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LSTM model with 50% test accuracy \n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, dropout=0.1, recurrent_dropout=0.1,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()\n",
    "optimizer=Adam(learning_rate = 0.001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer , metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=16, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_199 (Dense)           (None, 721, 300)          30900     \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 721, 150)          45150     \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 721, 75)           11325     \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 721, 30)           2280      \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 721, 6)            186       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89841 (350.94 KB)\n",
      "Trainable params: 89841 (350.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "2/2 - 1s - loss: 1.7808 - accuracy: 0.1901 - val_loss: 1.7221 - val_accuracy: 0.5192 - 988ms/epoch - 494ms/step\n",
      "Epoch 2/500\n",
      "2/2 - 0s - loss: 1.7240 - accuracy: 0.4707 - val_loss: 1.6695 - val_accuracy: 0.5194 - 66ms/epoch - 33ms/step\n",
      "Epoch 3/500\n",
      "2/2 - 0s - loss: 1.6735 - accuracy: 0.4709 - val_loss: 1.6164 - val_accuracy: 0.5194 - 64ms/epoch - 32ms/step\n",
      "Epoch 4/500\n",
      "2/2 - 0s - loss: 1.6244 - accuracy: 0.4706 - val_loss: 1.5576 - val_accuracy: 0.5194 - 65ms/epoch - 32ms/step\n",
      "Epoch 5/500\n",
      "2/2 - 0s - loss: 1.5720 - accuracy: 0.4706 - val_loss: 1.5019 - val_accuracy: 0.5194 - 64ms/epoch - 32ms/step\n",
      "Epoch 6/500\n",
      "2/2 - 0s - loss: 1.5236 - accuracy: 0.4706 - val_loss: 1.4644 - val_accuracy: 0.5194 - 64ms/epoch - 32ms/step\n",
      "Epoch 7/500\n",
      "2/2 - 0s - loss: 1.4955 - accuracy: 0.4706 - val_loss: 1.4605 - val_accuracy: 0.5192 - 63ms/epoch - 31ms/step\n",
      "Epoch 8/500\n",
      "2/2 - 0s - loss: 1.5057 - accuracy: 0.4705 - val_loss: 1.4766 - val_accuracy: 0.5194 - 63ms/epoch - 32ms/step\n",
      "Epoch 9/500\n",
      "2/2 - 0s - loss: 1.5093 - accuracy: 0.4707 - val_loss: 1.4764 - val_accuracy: 0.5196 - 65ms/epoch - 33ms/step\n",
      "Epoch 10/500\n",
      "2/2 - 0s - loss: 1.4976 - accuracy: 0.4709 - val_loss: 1.4666 - val_accuracy: 0.5201 - 66ms/epoch - 33ms/step\n",
      "Epoch 11/500\n",
      "2/2 - 0s - loss: 1.4817 - accuracy: 0.4711 - val_loss: 1.4642 - val_accuracy: 0.5220 - 69ms/epoch - 34ms/step\n",
      "Epoch 12/500\n",
      "2/2 - 0s - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.4578 - val_accuracy: 0.5231 - 71ms/epoch - 35ms/step\n",
      "Epoch 13/500\n",
      "2/2 - 0s - loss: 1.4787 - accuracy: 0.4701 - val_loss: 1.4450 - val_accuracy: 0.5236 - 66ms/epoch - 33ms/step\n",
      "Epoch 14/500\n",
      "2/2 - 0s - loss: 1.4702 - accuracy: 0.4700 - val_loss: 1.4355 - val_accuracy: 0.5236 - 70ms/epoch - 35ms/step\n",
      "Epoch 15/500\n",
      "2/2 - 0s - loss: 1.4633 - accuracy: 0.4700 - val_loss: 1.4280 - val_accuracy: 0.5238 - 70ms/epoch - 35ms/step\n",
      "Epoch 16/500\n",
      "2/2 - 0s - loss: 1.4601 - accuracy: 0.4702 - val_loss: 1.4178 - val_accuracy: 0.5240 - 66ms/epoch - 33ms/step\n",
      "Epoch 17/500\n",
      "2/2 - 0s - loss: 1.4558 - accuracy: 0.4703 - val_loss: 1.4068 - val_accuracy: 0.5243 - 70ms/epoch - 35ms/step\n",
      "Epoch 18/500\n",
      "2/2 - 0s - loss: 1.4489 - accuracy: 0.4703 - val_loss: 1.4017 - val_accuracy: 0.5247 - 69ms/epoch - 35ms/step\n",
      "Epoch 19/500\n",
      "2/2 - 0s - loss: 1.4425 - accuracy: 0.4702 - val_loss: 1.4034 - val_accuracy: 0.5247 - 70ms/epoch - 35ms/step\n",
      "Epoch 20/500\n",
      "2/2 - 0s - loss: 1.4347 - accuracy: 0.4702 - val_loss: 1.4099 - val_accuracy: 0.5243 - 64ms/epoch - 32ms/step\n",
      "Epoch 21/500\n",
      "2/2 - 0s - loss: 1.4288 - accuracy: 0.4706 - val_loss: 1.4111 - val_accuracy: 0.5238 - 69ms/epoch - 34ms/step\n",
      "Epoch 22/500\n",
      "2/2 - 0s - loss: 1.4236 - accuracy: 0.4703 - val_loss: 1.3981 - val_accuracy: 0.5238 - 65ms/epoch - 33ms/step\n",
      "Epoch 23/500\n",
      "2/2 - 0s - loss: 1.4142 - accuracy: 0.4701 - val_loss: 1.3794 - val_accuracy: 0.5236 - 68ms/epoch - 34ms/step\n",
      "Epoch 24/500\n",
      "2/2 - 0s - loss: 1.4095 - accuracy: 0.4706 - val_loss: 1.3656 - val_accuracy: 0.5240 - 68ms/epoch - 34ms/step\n",
      "Epoch 25/500\n",
      "2/2 - 0s - loss: 1.4059 - accuracy: 0.4702 - val_loss: 1.3572 - val_accuracy: 0.5245 - 66ms/epoch - 33ms/step\n",
      "Epoch 26/500\n",
      "2/2 - 0s - loss: 1.4010 - accuracy: 0.4702 - val_loss: 1.3558 - val_accuracy: 0.5245 - 67ms/epoch - 34ms/step\n",
      "Epoch 27/500\n",
      "2/2 - 0s - loss: 1.3889 - accuracy: 0.4702 - val_loss: 1.3498 - val_accuracy: 0.5238 - 67ms/epoch - 33ms/step\n",
      "Epoch 28/500\n",
      "2/2 - 0s - loss: 1.3796 - accuracy: 0.4703 - val_loss: 1.3452 - val_accuracy: 0.5236 - 69ms/epoch - 35ms/step\n",
      "Epoch 29/500\n",
      "2/2 - 0s - loss: 1.3706 - accuracy: 0.4702 - val_loss: 1.3311 - val_accuracy: 0.5243 - 74ms/epoch - 37ms/step\n",
      "Epoch 30/500\n",
      "2/2 - 0s - loss: 1.3652 - accuracy: 0.4706 - val_loss: 1.3239 - val_accuracy: 0.5243 - 70ms/epoch - 35ms/step\n",
      "Epoch 31/500\n",
      "2/2 - 0s - loss: 1.3581 - accuracy: 0.4707 - val_loss: 1.3270 - val_accuracy: 0.5236 - 65ms/epoch - 33ms/step\n",
      "Epoch 32/500\n",
      "2/2 - 0s - loss: 1.3469 - accuracy: 0.4707 - val_loss: 1.3316 - val_accuracy: 0.5236 - 67ms/epoch - 34ms/step\n",
      "Epoch 33/500\n",
      "2/2 - 0s - loss: 1.3417 - accuracy: 0.4698 - val_loss: 1.3284 - val_accuracy: 0.5236 - 64ms/epoch - 32ms/step\n",
      "Epoch 34/500\n",
      "2/2 - 0s - loss: 1.3321 - accuracy: 0.4709 - val_loss: 1.3242 - val_accuracy: 0.5233 - 66ms/epoch - 33ms/step\n",
      "Epoch 35/500\n",
      "2/2 - 0s - loss: 1.3269 - accuracy: 0.4714 - val_loss: 1.3158 - val_accuracy: 0.5250 - 65ms/epoch - 33ms/step\n",
      "Epoch 36/500\n",
      "2/2 - 0s - loss: 1.3134 - accuracy: 0.4841 - val_loss: 1.3094 - val_accuracy: 0.5368 - 74ms/epoch - 37ms/step\n",
      "Epoch 37/500\n",
      "2/2 - 0s - loss: 1.3127 - accuracy: 0.4939 - val_loss: 1.2905 - val_accuracy: 0.5354 - 74ms/epoch - 37ms/step\n",
      "Epoch 38/500\n",
      "2/2 - 0s - loss: 1.2980 - accuracy: 0.4963 - val_loss: 1.2917 - val_accuracy: 0.5261 - 70ms/epoch - 35ms/step\n",
      "Epoch 39/500\n",
      "2/2 - 0s - loss: 1.2905 - accuracy: 0.4863 - val_loss: 1.2884 - val_accuracy: 0.5305 - 70ms/epoch - 35ms/step\n",
      "Epoch 40/500\n",
      "2/2 - 0s - loss: 1.2784 - accuracy: 0.4912 - val_loss: 1.2809 - val_accuracy: 0.5395 - 71ms/epoch - 36ms/step\n",
      "Epoch 41/500\n",
      "2/2 - 0s - loss: 1.2722 - accuracy: 0.5047 - val_loss: 1.2858 - val_accuracy: 0.5395 - 66ms/epoch - 33ms/step\n",
      "Epoch 42/500\n",
      "2/2 - 0s - loss: 1.2754 - accuracy: 0.4989 - val_loss: 1.2604 - val_accuracy: 0.5368 - 69ms/epoch - 34ms/step\n",
      "Epoch 43/500\n",
      "2/2 - 0s - loss: 1.2559 - accuracy: 0.4999 - val_loss: 1.2437 - val_accuracy: 0.5363 - 67ms/epoch - 34ms/step\n",
      "Epoch 44/500\n",
      "2/2 - 0s - loss: 1.2437 - accuracy: 0.5000 - val_loss: 1.2518 - val_accuracy: 0.5379 - 72ms/epoch - 36ms/step\n",
      "Epoch 45/500\n",
      "2/2 - 0s - loss: 1.2361 - accuracy: 0.5069 - val_loss: 1.2585 - val_accuracy: 0.5351 - 71ms/epoch - 35ms/step\n",
      "Epoch 46/500\n",
      "2/2 - 0s - loss: 1.2356 - accuracy: 0.5083 - val_loss: 1.2316 - val_accuracy: 0.5430 - 75ms/epoch - 38ms/step\n",
      "Epoch 47/500\n",
      "2/2 - 0s - loss: 1.2197 - accuracy: 0.5151 - val_loss: 1.2383 - val_accuracy: 0.5337 - 73ms/epoch - 36ms/step\n",
      "Epoch 48/500\n",
      "2/2 - 0s - loss: 1.2156 - accuracy: 0.5061 - val_loss: 1.2437 - val_accuracy: 0.5331 - 73ms/epoch - 37ms/step\n",
      "Epoch 49/500\n",
      "2/2 - 0s - loss: 1.2047 - accuracy: 0.5136 - val_loss: 1.2478 - val_accuracy: 0.5439 - 71ms/epoch - 36ms/step\n",
      "Epoch 50/500\n",
      "2/2 - 0s - loss: 1.2043 - accuracy: 0.5327 - val_loss: 1.2391 - val_accuracy: 0.5379 - 66ms/epoch - 33ms/step\n",
      "Epoch 51/500\n",
      "2/2 - 0s - loss: 1.1835 - accuracy: 0.5270 - val_loss: 1.2199 - val_accuracy: 0.5381 - 72ms/epoch - 36ms/step\n",
      "Epoch 52/500\n",
      "2/2 - 0s - loss: 1.1905 - accuracy: 0.5119 - val_loss: 1.2201 - val_accuracy: 0.5331 - 75ms/epoch - 38ms/step\n",
      "Epoch 53/500\n",
      "2/2 - 0s - loss: 1.1766 - accuracy: 0.5182 - val_loss: 1.2420 - val_accuracy: 0.5342 - 73ms/epoch - 37ms/step\n",
      "Epoch 54/500\n",
      "2/2 - 0s - loss: 1.1804 - accuracy: 0.5339 - val_loss: 1.2566 - val_accuracy: 0.4824 - 70ms/epoch - 35ms/step\n",
      "Epoch 55/500\n",
      "2/2 - 0s - loss: 1.1763 - accuracy: 0.5371 - val_loss: 1.2083 - val_accuracy: 0.5529 - 71ms/epoch - 35ms/step\n",
      "Epoch 56/500\n",
      "2/2 - 0s - loss: 1.1548 - accuracy: 0.5301 - val_loss: 1.2089 - val_accuracy: 0.5411 - 71ms/epoch - 36ms/step\n",
      "Epoch 57/500\n",
      "2/2 - 0s - loss: 1.1649 - accuracy: 0.5171 - val_loss: 1.2017 - val_accuracy: 0.5615 - 80ms/epoch - 40ms/step\n",
      "Epoch 58/500\n",
      "2/2 - 0s - loss: 1.1572 - accuracy: 0.5473 - val_loss: 1.2090 - val_accuracy: 0.5613 - 67ms/epoch - 33ms/step\n",
      "Epoch 59/500\n",
      "2/2 - 0s - loss: 1.1258 - accuracy: 0.5573 - val_loss: 1.2606 - val_accuracy: 0.5266 - 68ms/epoch - 34ms/step\n",
      "Epoch 60/500\n",
      "2/2 - 0s - loss: 1.1844 - accuracy: 0.5171 - val_loss: 1.2038 - val_accuracy: 0.5543 - 68ms/epoch - 34ms/step\n",
      "Epoch 61/500\n",
      "2/2 - 0s - loss: 1.1297 - accuracy: 0.5685 - val_loss: 1.2047 - val_accuracy: 0.5589 - 66ms/epoch - 33ms/step\n",
      "Epoch 62/500\n",
      "2/2 - 0s - loss: 1.1526 - accuracy: 0.5492 - val_loss: 1.1945 - val_accuracy: 0.5721 - 68ms/epoch - 34ms/step\n",
      "Epoch 63/500\n",
      "2/2 - 0s - loss: 1.1138 - accuracy: 0.5541 - val_loss: 1.2086 - val_accuracy: 0.5289 - 71ms/epoch - 36ms/step\n",
      "Epoch 64/500\n",
      "2/2 - 0s - loss: 1.1240 - accuracy: 0.5795 - val_loss: 1.1959 - val_accuracy: 0.5453 - 71ms/epoch - 36ms/step\n",
      "Epoch 65/500\n",
      "2/2 - 0s - loss: 1.1099 - accuracy: 0.5785 - val_loss: 1.1802 - val_accuracy: 0.5650 - 70ms/epoch - 35ms/step\n",
      "Epoch 66/500\n",
      "2/2 - 0s - loss: 1.1171 - accuracy: 0.5481 - val_loss: 1.1827 - val_accuracy: 0.5573 - 66ms/epoch - 33ms/step\n",
      "Epoch 67/500\n",
      "2/2 - 0s - loss: 1.1044 - accuracy: 0.5726 - val_loss: 1.2209 - val_accuracy: 0.5331 - 65ms/epoch - 32ms/step\n",
      "Epoch 68/500\n",
      "2/2 - 0s - loss: 1.1097 - accuracy: 0.5828 - val_loss: 1.2197 - val_accuracy: 0.5377 - 65ms/epoch - 33ms/step\n",
      "Epoch 69/500\n",
      "2/2 - 0s - loss: 1.0954 - accuracy: 0.5795 - val_loss: 1.2062 - val_accuracy: 0.5321 - 69ms/epoch - 34ms/step\n",
      "Epoch 70/500\n",
      "2/2 - 0s - loss: 1.0897 - accuracy: 0.5873 - val_loss: 1.1623 - val_accuracy: 0.5684 - 71ms/epoch - 35ms/step\n",
      "Epoch 71/500\n",
      "2/2 - 0s - loss: 1.0926 - accuracy: 0.5695 - val_loss: 1.1530 - val_accuracy: 0.5765 - 66ms/epoch - 33ms/step\n",
      "Epoch 72/500\n",
      "2/2 - 0s - loss: 1.0858 - accuracy: 0.5764 - val_loss: 1.1935 - val_accuracy: 0.5414 - 72ms/epoch - 36ms/step\n",
      "Epoch 73/500\n",
      "2/2 - 0s - loss: 1.0734 - accuracy: 0.6027 - val_loss: 1.2056 - val_accuracy: 0.5305 - 65ms/epoch - 33ms/step\n",
      "Epoch 74/500\n",
      "2/2 - 0s - loss: 1.0717 - accuracy: 0.5998 - val_loss: 1.1733 - val_accuracy: 0.5666 - 63ms/epoch - 32ms/step\n",
      "Epoch 75/500\n",
      "2/2 - 0s - loss: 1.0704 - accuracy: 0.5867 - val_loss: 1.1770 - val_accuracy: 0.5615 - 65ms/epoch - 33ms/step\n",
      "Epoch 76/500\n",
      "2/2 - 0s - loss: 1.0620 - accuracy: 0.6033 - val_loss: 1.1819 - val_accuracy: 0.5550 - 65ms/epoch - 32ms/step\n",
      "Epoch 77/500\n",
      "2/2 - 0s - loss: 1.0592 - accuracy: 0.5998 - val_loss: 1.1808 - val_accuracy: 0.5559 - 64ms/epoch - 32ms/step\n",
      "Epoch 78/500\n",
      "2/2 - 0s - loss: 1.0574 - accuracy: 0.5960 - val_loss: 1.2018 - val_accuracy: 0.5365 - 63ms/epoch - 31ms/step\n",
      "Epoch 79/500\n",
      "2/2 - 0s - loss: 1.0502 - accuracy: 0.6045 - val_loss: 1.2076 - val_accuracy: 0.5328 - 68ms/epoch - 34ms/step\n",
      "Epoch 80/500\n",
      "2/2 - 0s - loss: 1.0477 - accuracy: 0.6050 - val_loss: 1.2154 - val_accuracy: 0.5190 - 69ms/epoch - 34ms/step\n",
      "Epoch 81/500\n",
      "2/2 - 0s - loss: 1.0421 - accuracy: 0.6125 - val_loss: 1.2031 - val_accuracy: 0.5331 - 68ms/epoch - 34ms/step\n",
      "Epoch 82/500\n",
      "2/2 - 0s - loss: 1.0399 - accuracy: 0.6113 - val_loss: 1.2017 - val_accuracy: 0.5314 - 68ms/epoch - 34ms/step\n",
      "Epoch 83/500\n",
      "2/2 - 0s - loss: 1.0408 - accuracy: 0.6147 - val_loss: 1.2365 - val_accuracy: 0.4931 - 70ms/epoch - 35ms/step\n",
      "Epoch 84/500\n",
      "2/2 - 0s - loss: 1.0495 - accuracy: 0.6105 - val_loss: 1.1758 - val_accuracy: 0.5546 - 66ms/epoch - 33ms/step\n",
      "Epoch 85/500\n",
      "2/2 - 0s - loss: 1.0429 - accuracy: 0.5973 - val_loss: 1.2010 - val_accuracy: 0.5324 - 67ms/epoch - 34ms/step\n",
      "Epoch 86/500\n",
      "2/2 - 0s - loss: 1.0307 - accuracy: 0.6152 - val_loss: 1.2793 - val_accuracy: 0.4508 - 74ms/epoch - 37ms/step\n",
      "Epoch 87/500\n",
      "2/2 - 0s - loss: 1.0558 - accuracy: 0.5938 - val_loss: 1.1910 - val_accuracy: 0.5414 - 70ms/epoch - 35ms/step\n",
      "Epoch 88/500\n",
      "2/2 - 0s - loss: 1.0245 - accuracy: 0.6199 - val_loss: 1.1789 - val_accuracy: 0.5525 - 68ms/epoch - 34ms/step\n",
      "Epoch 89/500\n",
      "2/2 - 0s - loss: 1.0277 - accuracy: 0.6198 - val_loss: 1.1804 - val_accuracy: 0.5476 - 66ms/epoch - 33ms/step\n",
      "Epoch 90/500\n",
      "2/2 - 0s - loss: 1.0227 - accuracy: 0.6202 - val_loss: 1.1851 - val_accuracy: 0.5458 - 65ms/epoch - 32ms/step\n",
      "Epoch 91/500\n",
      "2/2 - 0s - loss: 1.0228 - accuracy: 0.6141 - val_loss: 1.1974 - val_accuracy: 0.5411 - 65ms/epoch - 33ms/step\n",
      "Epoch 92/500\n",
      "2/2 - 0s - loss: 1.0171 - accuracy: 0.6233 - val_loss: 1.2191 - val_accuracy: 0.5192 - 65ms/epoch - 32ms/step\n",
      "Epoch 93/500\n",
      "2/2 - 0s - loss: 1.0271 - accuracy: 0.6204 - val_loss: 1.1805 - val_accuracy: 0.5520 - 66ms/epoch - 33ms/step\n",
      "Epoch 94/500\n",
      "2/2 - 0s - loss: 1.0164 - accuracy: 0.6161 - val_loss: 1.2204 - val_accuracy: 0.5065 - 64ms/epoch - 32ms/step\n",
      "Epoch 95/500\n",
      "2/2 - 0s - loss: 1.0164 - accuracy: 0.6198 - val_loss: 1.2754 - val_accuracy: 0.4628 - 64ms/epoch - 32ms/step\n",
      "Epoch 96/500\n",
      "2/2 - 0s - loss: 1.0276 - accuracy: 0.6094 - val_loss: 1.1865 - val_accuracy: 0.5455 - 65ms/epoch - 33ms/step\n",
      "Epoch 97/500\n",
      "2/2 - 0s - loss: 1.0210 - accuracy: 0.6110 - val_loss: 1.1886 - val_accuracy: 0.5488 - 66ms/epoch - 33ms/step\n",
      "Epoch 98/500\n",
      "2/2 - 0s - loss: 1.0131 - accuracy: 0.6190 - val_loss: 1.2252 - val_accuracy: 0.5143 - 69ms/epoch - 35ms/step\n",
      "Epoch 99/500\n",
      "2/2 - 0s - loss: 1.0149 - accuracy: 0.6204 - val_loss: 1.1900 - val_accuracy: 0.5455 - 68ms/epoch - 34ms/step\n",
      "Epoch 100/500\n",
      "2/2 - 0s - loss: 1.0090 - accuracy: 0.6250 - val_loss: 1.1928 - val_accuracy: 0.5472 - 67ms/epoch - 34ms/step\n",
      "Epoch 101/500\n",
      "2/2 - 0s - loss: 1.0041 - accuracy: 0.6248 - val_loss: 1.2139 - val_accuracy: 0.5201 - 71ms/epoch - 36ms/step\n",
      "Epoch 102/500\n",
      "2/2 - 0s - loss: 1.0161 - accuracy: 0.6163 - val_loss: 1.2274 - val_accuracy: 0.5116 - 74ms/epoch - 37ms/step\n",
      "Epoch 103/500\n",
      "2/2 - 0s - loss: 1.0118 - accuracy: 0.6182 - val_loss: 1.2043 - val_accuracy: 0.5423 - 71ms/epoch - 35ms/step\n",
      "Epoch 104/500\n",
      "2/2 - 0s - loss: 1.0184 - accuracy: 0.6224 - val_loss: 1.1639 - val_accuracy: 0.5744 - 70ms/epoch - 35ms/step\n",
      "Epoch 105/500\n",
      "2/2 - 0s - loss: 1.0196 - accuracy: 0.6055 - val_loss: 1.1803 - val_accuracy: 0.5543 - 70ms/epoch - 35ms/step\n",
      "Epoch 106/500\n",
      "2/2 - 0s - loss: 1.0140 - accuracy: 0.6173 - val_loss: 1.2784 - val_accuracy: 0.4646 - 68ms/epoch - 34ms/step\n",
      "Epoch 107/500\n",
      "2/2 - 0s - loss: 1.0245 - accuracy: 0.6043 - val_loss: 1.2026 - val_accuracy: 0.5280 - 65ms/epoch - 33ms/step\n",
      "Epoch 108/500\n",
      "2/2 - 0s - loss: 1.0065 - accuracy: 0.6190 - val_loss: 1.1758 - val_accuracy: 0.5601 - 66ms/epoch - 33ms/step\n",
      "Epoch 109/500\n",
      "2/2 - 0s - loss: 1.0128 - accuracy: 0.6230 - val_loss: 1.1860 - val_accuracy: 0.5555 - 68ms/epoch - 34ms/step\n",
      "Epoch 110/500\n",
      "2/2 - 0s - loss: 1.0157 - accuracy: 0.6226 - val_loss: 1.2084 - val_accuracy: 0.5398 - 66ms/epoch - 33ms/step\n",
      "Epoch 111/500\n",
      "2/2 - 0s - loss: 0.9998 - accuracy: 0.6226 - val_loss: 1.2635 - val_accuracy: 0.4792 - 66ms/epoch - 33ms/step\n",
      "Epoch 112/500\n",
      "2/2 - 0s - loss: 1.0133 - accuracy: 0.6122 - val_loss: 1.2509 - val_accuracy: 0.4820 - 64ms/epoch - 32ms/step\n",
      "Epoch 113/500\n",
      "2/2 - 0s - loss: 1.0042 - accuracy: 0.6204 - val_loss: 1.1597 - val_accuracy: 0.5626 - 66ms/epoch - 33ms/step\n",
      "Epoch 114/500\n",
      "2/2 - 0s - loss: 1.0216 - accuracy: 0.6071 - val_loss: 1.1966 - val_accuracy: 0.5442 - 70ms/epoch - 35ms/step\n",
      "Epoch 115/500\n",
      "2/2 - 0s - loss: 1.0224 - accuracy: 0.6215 - val_loss: 1.2205 - val_accuracy: 0.5294 - 67ms/epoch - 33ms/step\n",
      "Epoch 116/500\n",
      "2/2 - 0s - loss: 0.9968 - accuracy: 0.6253 - val_loss: 1.2054 - val_accuracy: 0.5411 - 69ms/epoch - 35ms/step\n",
      "Epoch 117/500\n",
      "2/2 - 0s - loss: 1.0443 - accuracy: 0.5954 - val_loss: 1.2663 - val_accuracy: 0.4824 - 69ms/epoch - 34ms/step\n",
      "Epoch 118/500\n",
      "2/2 - 0s - loss: 1.0078 - accuracy: 0.6155 - val_loss: 1.1811 - val_accuracy: 0.5448 - 67ms/epoch - 33ms/step\n",
      "Epoch 119/500\n",
      "2/2 - 0s - loss: 1.0007 - accuracy: 0.6243 - val_loss: 1.1641 - val_accuracy: 0.5631 - 66ms/epoch - 33ms/step\n",
      "Epoch 120/500\n",
      "2/2 - 0s - loss: 0.9864 - accuracy: 0.6316 - val_loss: 1.2405 - val_accuracy: 0.5039 - 67ms/epoch - 33ms/step\n",
      "Epoch 121/500\n",
      "2/2 - 0s - loss: 1.0050 - accuracy: 0.6243 - val_loss: 1.2114 - val_accuracy: 0.5259 - 67ms/epoch - 34ms/step\n",
      "Epoch 122/500\n",
      "2/2 - 0s - loss: 0.9865 - accuracy: 0.6320 - val_loss: 1.1960 - val_accuracy: 0.5358 - 67ms/epoch - 33ms/step\n",
      "Epoch 123/500\n",
      "2/2 - 0s - loss: 0.9873 - accuracy: 0.6319 - val_loss: 1.1825 - val_accuracy: 0.5509 - 69ms/epoch - 35ms/step\n",
      "Epoch 124/500\n",
      "2/2 - 0s - loss: 0.9831 - accuracy: 0.6323 - val_loss: 1.1899 - val_accuracy: 0.5483 - 68ms/epoch - 34ms/step\n",
      "Epoch 125/500\n",
      "2/2 - 0s - loss: 0.9860 - accuracy: 0.6313 - val_loss: 1.2185 - val_accuracy: 0.5289 - 65ms/epoch - 32ms/step\n",
      "Epoch 126/500\n",
      "2/2 - 0s - loss: 0.9873 - accuracy: 0.6352 - val_loss: 1.1892 - val_accuracy: 0.5479 - 66ms/epoch - 33ms/step\n",
      "Epoch 127/500\n",
      "2/2 - 0s - loss: 0.9843 - accuracy: 0.6309 - val_loss: 1.1984 - val_accuracy: 0.5344 - 69ms/epoch - 34ms/step\n",
      "Epoch 128/500\n",
      "2/2 - 0s - loss: 0.9842 - accuracy: 0.6311 - val_loss: 1.2122 - val_accuracy: 0.5282 - 66ms/epoch - 33ms/step\n",
      "Epoch 129/500\n",
      "2/2 - 0s - loss: 0.9861 - accuracy: 0.6338 - val_loss: 1.1635 - val_accuracy: 0.5615 - 66ms/epoch - 33ms/step\n",
      "Epoch 130/500\n",
      "2/2 - 0s - loss: 0.9843 - accuracy: 0.6287 - val_loss: 1.1976 - val_accuracy: 0.5460 - 65ms/epoch - 32ms/step\n",
      "Epoch 131/500\n",
      "2/2 - 0s - loss: 0.9809 - accuracy: 0.6369 - val_loss: 1.2104 - val_accuracy: 0.5384 - 66ms/epoch - 33ms/step\n",
      "Epoch 132/500\n",
      "2/2 - 0s - loss: 0.9794 - accuracy: 0.6368 - val_loss: 1.1779 - val_accuracy: 0.5511 - 68ms/epoch - 34ms/step\n",
      "Epoch 133/500\n",
      "2/2 - 0s - loss: 0.9807 - accuracy: 0.6300 - val_loss: 1.2026 - val_accuracy: 0.5372 - 72ms/epoch - 36ms/step\n",
      "Epoch 134/500\n",
      "2/2 - 0s - loss: 0.9869 - accuracy: 0.6347 - val_loss: 1.1808 - val_accuracy: 0.5481 - 67ms/epoch - 34ms/step\n",
      "Epoch 135/500\n",
      "2/2 - 0s - loss: 0.9780 - accuracy: 0.6354 - val_loss: 1.1802 - val_accuracy: 0.5534 - 67ms/epoch - 34ms/step\n",
      "Epoch 136/500\n",
      "2/2 - 0s - loss: 0.9814 - accuracy: 0.6280 - val_loss: 1.2510 - val_accuracy: 0.5150 - 67ms/epoch - 33ms/step\n",
      "Epoch 137/500\n",
      "2/2 - 0s - loss: 0.9806 - accuracy: 0.6293 - val_loss: 1.1934 - val_accuracy: 0.5472 - 69ms/epoch - 35ms/step\n",
      "Epoch 138/500\n",
      "2/2 - 0s - loss: 0.9758 - accuracy: 0.6330 - val_loss: 1.1997 - val_accuracy: 0.5416 - 69ms/epoch - 34ms/step\n",
      "Epoch 139/500\n",
      "2/2 - 0s - loss: 0.9748 - accuracy: 0.6392 - val_loss: 1.2109 - val_accuracy: 0.5340 - 68ms/epoch - 34ms/step\n",
      "Epoch 140/500\n",
      "2/2 - 0s - loss: 0.9791 - accuracy: 0.6354 - val_loss: 1.1878 - val_accuracy: 0.5509 - 66ms/epoch - 33ms/step\n",
      "Epoch 141/500\n",
      "2/2 - 0s - loss: 0.9749 - accuracy: 0.6327 - val_loss: 1.2095 - val_accuracy: 0.5409 - 68ms/epoch - 34ms/step\n",
      "Epoch 142/500\n",
      "2/2 - 0s - loss: 0.9711 - accuracy: 0.6376 - val_loss: 1.2089 - val_accuracy: 0.5435 - 64ms/epoch - 32ms/step\n",
      "Epoch 143/500\n",
      "2/2 - 0s - loss: 0.9696 - accuracy: 0.6391 - val_loss: 1.2006 - val_accuracy: 0.5423 - 65ms/epoch - 32ms/step\n",
      "Epoch 144/500\n",
      "2/2 - 0s - loss: 0.9659 - accuracy: 0.6417 - val_loss: 1.2054 - val_accuracy: 0.5342 - 67ms/epoch - 33ms/step\n",
      "Epoch 145/500\n",
      "2/2 - 0s - loss: 0.9792 - accuracy: 0.6337 - val_loss: 1.1870 - val_accuracy: 0.5405 - 66ms/epoch - 33ms/step\n",
      "Epoch 146/500\n",
      "2/2 - 0s - loss: 0.9712 - accuracy: 0.6379 - val_loss: 1.1836 - val_accuracy: 0.5490 - 64ms/epoch - 32ms/step\n",
      "Epoch 147/500\n",
      "2/2 - 0s - loss: 0.9648 - accuracy: 0.6446 - val_loss: 1.1748 - val_accuracy: 0.5631 - 65ms/epoch - 32ms/step\n",
      "Epoch 148/500\n",
      "2/2 - 0s - loss: 0.9729 - accuracy: 0.6352 - val_loss: 1.2365 - val_accuracy: 0.5233 - 69ms/epoch - 34ms/step\n",
      "Epoch 149/500\n",
      "2/2 - 0s - loss: 0.9765 - accuracy: 0.6356 - val_loss: 1.1946 - val_accuracy: 0.5442 - 69ms/epoch - 34ms/step\n",
      "Epoch 150/500\n",
      "2/2 - 0s - loss: 0.9719 - accuracy: 0.6380 - val_loss: 1.1720 - val_accuracy: 0.5580 - 70ms/epoch - 35ms/step\n",
      "Epoch 151/500\n",
      "2/2 - 0s - loss: 0.9684 - accuracy: 0.6354 - val_loss: 1.2383 - val_accuracy: 0.5125 - 69ms/epoch - 34ms/step\n",
      "Epoch 152/500\n",
      "2/2 - 0s - loss: 0.9686 - accuracy: 0.6346 - val_loss: 1.1769 - val_accuracy: 0.5576 - 65ms/epoch - 32ms/step\n",
      "Epoch 153/500\n",
      "2/2 - 0s - loss: 0.9757 - accuracy: 0.6293 - val_loss: 1.2008 - val_accuracy: 0.5504 - 63ms/epoch - 32ms/step\n",
      "Epoch 154/500\n",
      "2/2 - 0s - loss: 0.9666 - accuracy: 0.6412 - val_loss: 1.2142 - val_accuracy: 0.5414 - 65ms/epoch - 33ms/step\n",
      "Epoch 155/500\n",
      "2/2 - 0s - loss: 0.9675 - accuracy: 0.6385 - val_loss: 1.1679 - val_accuracy: 0.5576 - 68ms/epoch - 34ms/step\n",
      "Epoch 156/500\n",
      "2/2 - 0s - loss: 0.9692 - accuracy: 0.6354 - val_loss: 1.1736 - val_accuracy: 0.5490 - 70ms/epoch - 35ms/step\n",
      "Epoch 157/500\n",
      "2/2 - 0s - loss: 0.9613 - accuracy: 0.6417 - val_loss: 1.1880 - val_accuracy: 0.5483 - 71ms/epoch - 35ms/step\n",
      "Epoch 158/500\n",
      "2/2 - 0s - loss: 0.9653 - accuracy: 0.6461 - val_loss: 1.1909 - val_accuracy: 0.5552 - 68ms/epoch - 34ms/step\n",
      "Epoch 159/500\n",
      "2/2 - 0s - loss: 0.9673 - accuracy: 0.6417 - val_loss: 1.1647 - val_accuracy: 0.5680 - 69ms/epoch - 34ms/step\n",
      "Epoch 160/500\n",
      "2/2 - 0s - loss: 0.9791 - accuracy: 0.6265 - val_loss: 1.2093 - val_accuracy: 0.5337 - 67ms/epoch - 34ms/step\n",
      "Epoch 161/500\n",
      "2/2 - 0s - loss: 0.9611 - accuracy: 0.6408 - val_loss: 1.2224 - val_accuracy: 0.5275 - 63ms/epoch - 32ms/step\n",
      "Epoch 162/500\n",
      "2/2 - 0s - loss: 0.9645 - accuracy: 0.6404 - val_loss: 1.1494 - val_accuracy: 0.5719 - 66ms/epoch - 33ms/step\n",
      "Epoch 163/500\n",
      "2/2 - 0s - loss: 0.9629 - accuracy: 0.6385 - val_loss: 1.1833 - val_accuracy: 0.5562 - 64ms/epoch - 32ms/step\n",
      "Epoch 164/500\n",
      "2/2 - 0s - loss: 0.9617 - accuracy: 0.6461 - val_loss: 1.1927 - val_accuracy: 0.5518 - 64ms/epoch - 32ms/step\n",
      "Epoch 165/500\n",
      "2/2 - 0s - loss: 0.9589 - accuracy: 0.6426 - val_loss: 1.1978 - val_accuracy: 0.5497 - 66ms/epoch - 33ms/step\n",
      "Epoch 166/500\n",
      "2/2 - 0s - loss: 0.9562 - accuracy: 0.6430 - val_loss: 1.2143 - val_accuracy: 0.5393 - 66ms/epoch - 33ms/step\n",
      "Epoch 167/500\n",
      "2/2 - 0s - loss: 0.9609 - accuracy: 0.6434 - val_loss: 1.1645 - val_accuracy: 0.5631 - 65ms/epoch - 32ms/step\n",
      "Epoch 168/500\n",
      "2/2 - 0s - loss: 0.9580 - accuracy: 0.6439 - val_loss: 1.1707 - val_accuracy: 0.5571 - 65ms/epoch - 32ms/step\n",
      "Epoch 169/500\n",
      "2/2 - 0s - loss: 0.9556 - accuracy: 0.6432 - val_loss: 1.2231 - val_accuracy: 0.5381 - 68ms/epoch - 34ms/step\n",
      "Epoch 170/500\n",
      "2/2 - 0s - loss: 0.9556 - accuracy: 0.6441 - val_loss: 1.1973 - val_accuracy: 0.5499 - 64ms/epoch - 32ms/step\n",
      "Epoch 171/500\n",
      "2/2 - 0s - loss: 0.9501 - accuracy: 0.6458 - val_loss: 1.1756 - val_accuracy: 0.5502 - 64ms/epoch - 32ms/step\n",
      "Epoch 172/500\n",
      "2/2 - 0s - loss: 0.9498 - accuracy: 0.6466 - val_loss: 1.2150 - val_accuracy: 0.5268 - 63ms/epoch - 32ms/step\n",
      "Epoch 173/500\n",
      "2/2 - 0s - loss: 0.9598 - accuracy: 0.6468 - val_loss: 1.1552 - val_accuracy: 0.5640 - 65ms/epoch - 33ms/step\n",
      "Epoch 174/500\n",
      "2/2 - 0s - loss: 0.9642 - accuracy: 0.6374 - val_loss: 1.1702 - val_accuracy: 0.5613 - 64ms/epoch - 32ms/step\n",
      "Epoch 175/500\n",
      "2/2 - 0s - loss: 0.9541 - accuracy: 0.6416 - val_loss: 1.2439 - val_accuracy: 0.5196 - 66ms/epoch - 33ms/step\n",
      "Epoch 176/500\n",
      "2/2 - 0s - loss: 0.9586 - accuracy: 0.6353 - val_loss: 1.1895 - val_accuracy: 0.5455 - 61ms/epoch - 30ms/step\n",
      "Epoch 177/500\n",
      "2/2 - 0s - loss: 0.9495 - accuracy: 0.6444 - val_loss: 1.1805 - val_accuracy: 0.5527 - 63ms/epoch - 31ms/step\n",
      "Epoch 178/500\n",
      "2/2 - 0s - loss: 0.9610 - accuracy: 0.6442 - val_loss: 1.1539 - val_accuracy: 0.5666 - 63ms/epoch - 32ms/step\n",
      "Epoch 179/500\n",
      "2/2 - 0s - loss: 0.9559 - accuracy: 0.6469 - val_loss: 1.1591 - val_accuracy: 0.5601 - 64ms/epoch - 32ms/step\n",
      "Epoch 180/500\n",
      "2/2 - 0s - loss: 0.9436 - accuracy: 0.6500 - val_loss: 1.2064 - val_accuracy: 0.5335 - 62ms/epoch - 31ms/step\n",
      "Epoch 181/500\n",
      "2/2 - 0s - loss: 0.9496 - accuracy: 0.6449 - val_loss: 1.1779 - val_accuracy: 0.5483 - 61ms/epoch - 31ms/step\n",
      "Epoch 182/500\n",
      "2/2 - 0s - loss: 0.9640 - accuracy: 0.6361 - val_loss: 1.1679 - val_accuracy: 0.5559 - 61ms/epoch - 30ms/step\n",
      "Epoch 183/500\n",
      "2/2 - 0s - loss: 0.9430 - accuracy: 0.6504 - val_loss: 1.1877 - val_accuracy: 0.5509 - 67ms/epoch - 34ms/step\n",
      "Epoch 184/500\n",
      "2/2 - 0s - loss: 0.9495 - accuracy: 0.6502 - val_loss: 1.1744 - val_accuracy: 0.5534 - 66ms/epoch - 33ms/step\n",
      "Epoch 185/500\n",
      "2/2 - 0s - loss: 0.9407 - accuracy: 0.6516 - val_loss: 1.2228 - val_accuracy: 0.5310 - 72ms/epoch - 36ms/step\n",
      "Epoch 186/500\n",
      "2/2 - 0s - loss: 0.9488 - accuracy: 0.6456 - val_loss: 1.1679 - val_accuracy: 0.5559 - 66ms/epoch - 33ms/step\n",
      "Epoch 187/500\n",
      "2/2 - 0s - loss: 0.9401 - accuracy: 0.6488 - val_loss: 1.1532 - val_accuracy: 0.5719 - 64ms/epoch - 32ms/step\n",
      "Epoch 188/500\n",
      "2/2 - 0s - loss: 0.9454 - accuracy: 0.6464 - val_loss: 1.2107 - val_accuracy: 0.5430 - 64ms/epoch - 32ms/step\n",
      "Epoch 189/500\n",
      "2/2 - 0s - loss: 0.9488 - accuracy: 0.6478 - val_loss: 1.1783 - val_accuracy: 0.5465 - 65ms/epoch - 32ms/step\n",
      "Epoch 190/500\n",
      "2/2 - 0s - loss: 0.9451 - accuracy: 0.6439 - val_loss: 1.2001 - val_accuracy: 0.5301 - 67ms/epoch - 33ms/step\n",
      "Epoch 191/500\n",
      "2/2 - 0s - loss: 0.9482 - accuracy: 0.6415 - val_loss: 1.2085 - val_accuracy: 0.5307 - 65ms/epoch - 32ms/step\n",
      "Epoch 192/500\n",
      "2/2 - 0s - loss: 0.9436 - accuracy: 0.6477 - val_loss: 1.1385 - val_accuracy: 0.5742 - 72ms/epoch - 36ms/step\n",
      "Epoch 193/500\n",
      "2/2 - 0s - loss: 0.9437 - accuracy: 0.6465 - val_loss: 1.1787 - val_accuracy: 0.5550 - 64ms/epoch - 32ms/step\n",
      "Epoch 194/500\n",
      "2/2 - 0s - loss: 0.9496 - accuracy: 0.6494 - val_loss: 1.1565 - val_accuracy: 0.5691 - 67ms/epoch - 33ms/step\n",
      "Epoch 195/500\n",
      "2/2 - 0s - loss: 0.9459 - accuracy: 0.6435 - val_loss: 1.1723 - val_accuracy: 0.5555 - 63ms/epoch - 31ms/step\n",
      "Epoch 196/500\n",
      "2/2 - 0s - loss: 0.9468 - accuracy: 0.6423 - val_loss: 1.3128 - val_accuracy: 0.4827 - 61ms/epoch - 31ms/step\n",
      "Epoch 197/500\n",
      "2/2 - 0s - loss: 0.9891 - accuracy: 0.6186 - val_loss: 1.1471 - val_accuracy: 0.5615 - 64ms/epoch - 32ms/step\n",
      "Epoch 198/500\n",
      "2/2 - 0s - loss: 0.9516 - accuracy: 0.6378 - val_loss: 1.1270 - val_accuracy: 0.5761 - 65ms/epoch - 32ms/step\n",
      "Epoch 199/500\n",
      "2/2 - 0s - loss: 0.9488 - accuracy: 0.6448 - val_loss: 1.2072 - val_accuracy: 0.5442 - 63ms/epoch - 32ms/step\n",
      "Epoch 200/500\n",
      "2/2 - 0s - loss: 0.9485 - accuracy: 0.6510 - val_loss: 1.2000 - val_accuracy: 0.5446 - 61ms/epoch - 31ms/step\n",
      "Epoch 201/500\n",
      "2/2 - 0s - loss: 0.9454 - accuracy: 0.6447 - val_loss: 1.2163 - val_accuracy: 0.5368 - 63ms/epoch - 31ms/step\n",
      "Epoch 202/500\n",
      "2/2 - 0s - loss: 0.9383 - accuracy: 0.6493 - val_loss: 1.1705 - val_accuracy: 0.5534 - 66ms/epoch - 33ms/step\n",
      "Epoch 203/500\n",
      "2/2 - 0s - loss: 0.9336 - accuracy: 0.6575 - val_loss: 1.1476 - val_accuracy: 0.5670 - 66ms/epoch - 33ms/step\n",
      "Epoch 204/500\n",
      "2/2 - 0s - loss: 0.9357 - accuracy: 0.6565 - val_loss: 1.1741 - val_accuracy: 0.5490 - 67ms/epoch - 33ms/step\n",
      "Epoch 205/500\n",
      "2/2 - 0s - loss: 0.9286 - accuracy: 0.6561 - val_loss: 1.1882 - val_accuracy: 0.5402 - 66ms/epoch - 33ms/step\n",
      "Epoch 206/500\n",
      "2/2 - 0s - loss: 0.9383 - accuracy: 0.6459 - val_loss: 1.1633 - val_accuracy: 0.5511 - 64ms/epoch - 32ms/step\n",
      "Epoch 207/500\n",
      "2/2 - 0s - loss: 0.9265 - accuracy: 0.6555 - val_loss: 1.1495 - val_accuracy: 0.5654 - 63ms/epoch - 31ms/step\n",
      "Epoch 208/500\n",
      "2/2 - 0s - loss: 0.9406 - accuracy: 0.6533 - val_loss: 1.1603 - val_accuracy: 0.5601 - 66ms/epoch - 33ms/step\n",
      "Epoch 209/500\n",
      "2/2 - 0s - loss: 0.9349 - accuracy: 0.6550 - val_loss: 1.2205 - val_accuracy: 0.5305 - 70ms/epoch - 35ms/step\n",
      "Epoch 210/500\n",
      "2/2 - 0s - loss: 0.9356 - accuracy: 0.6466 - val_loss: 1.2187 - val_accuracy: 0.5245 - 74ms/epoch - 37ms/step\n",
      "Epoch 211/500\n",
      "2/2 - 0s - loss: 0.9431 - accuracy: 0.6430 - val_loss: 1.1564 - val_accuracy: 0.5543 - 67ms/epoch - 33ms/step\n",
      "Epoch 212/500\n",
      "2/2 - 0s - loss: 0.9299 - accuracy: 0.6596 - val_loss: 1.1469 - val_accuracy: 0.5663 - 67ms/epoch - 34ms/step\n",
      "Epoch 213/500\n",
      "2/2 - 0s - loss: 0.9419 - accuracy: 0.6557 - val_loss: 1.1519 - val_accuracy: 0.5636 - 67ms/epoch - 34ms/step\n",
      "Epoch 214/500\n",
      "2/2 - 0s - loss: 0.9296 - accuracy: 0.6539 - val_loss: 1.1903 - val_accuracy: 0.5442 - 71ms/epoch - 35ms/step\n",
      "Epoch 215/500\n",
      "2/2 - 0s - loss: 0.9484 - accuracy: 0.6434 - val_loss: 1.2141 - val_accuracy: 0.5326 - 79ms/epoch - 40ms/step\n",
      "Epoch 216/500\n",
      "2/2 - 0s - loss: 0.9323 - accuracy: 0.6551 - val_loss: 1.1651 - val_accuracy: 0.5599 - 77ms/epoch - 38ms/step\n",
      "Epoch 217/500\n",
      "2/2 - 0s - loss: 0.9492 - accuracy: 0.6507 - val_loss: 1.1348 - val_accuracy: 0.5749 - 72ms/epoch - 36ms/step\n",
      "Epoch 218/500\n",
      "2/2 - 0s - loss: 0.9444 - accuracy: 0.6456 - val_loss: 1.2147 - val_accuracy: 0.5294 - 71ms/epoch - 36ms/step\n",
      "Epoch 219/500\n",
      "2/2 - 0s - loss: 0.9403 - accuracy: 0.6398 - val_loss: 1.1827 - val_accuracy: 0.5432 - 68ms/epoch - 34ms/step\n",
      "Epoch 220/500\n",
      "2/2 - 0s - loss: 0.9284 - accuracy: 0.6514 - val_loss: 1.1222 - val_accuracy: 0.5730 - 71ms/epoch - 36ms/step\n",
      "Epoch 221/500\n",
      "2/2 - 0s - loss: 0.9264 - accuracy: 0.6545 - val_loss: 1.1747 - val_accuracy: 0.5502 - 63ms/epoch - 32ms/step\n",
      "Epoch 222/500\n",
      "2/2 - 0s - loss: 0.9496 - accuracy: 0.6505 - val_loss: 1.1370 - val_accuracy: 0.5626 - 67ms/epoch - 33ms/step\n",
      "Epoch 223/500\n",
      "2/2 - 0s - loss: 0.9301 - accuracy: 0.6539 - val_loss: 1.1780 - val_accuracy: 0.5479 - 68ms/epoch - 34ms/step\n",
      "Epoch 224/500\n",
      "2/2 - 0s - loss: 0.9313 - accuracy: 0.6476 - val_loss: 1.2101 - val_accuracy: 0.5340 - 69ms/epoch - 35ms/step\n",
      "Epoch 225/500\n",
      "2/2 - 0s - loss: 0.9323 - accuracy: 0.6504 - val_loss: 1.1274 - val_accuracy: 0.5726 - 67ms/epoch - 33ms/step\n",
      "Epoch 226/500\n",
      "2/2 - 0s - loss: 0.9322 - accuracy: 0.6511 - val_loss: 1.1721 - val_accuracy: 0.5490 - 71ms/epoch - 36ms/step\n",
      "Epoch 227/500\n",
      "2/2 - 0s - loss: 0.9349 - accuracy: 0.6564 - val_loss: 1.1473 - val_accuracy: 0.5638 - 73ms/epoch - 36ms/step\n",
      "Epoch 228/500\n",
      "2/2 - 0s - loss: 0.9325 - accuracy: 0.6479 - val_loss: 1.1709 - val_accuracy: 0.5506 - 72ms/epoch - 36ms/step\n",
      "Epoch 229/500\n",
      "2/2 - 0s - loss: 0.9307 - accuracy: 0.6516 - val_loss: 1.1867 - val_accuracy: 0.5492 - 70ms/epoch - 35ms/step\n",
      "Epoch 230/500\n",
      "2/2 - 0s - loss: 0.9240 - accuracy: 0.6567 - val_loss: 1.1383 - val_accuracy: 0.5624 - 69ms/epoch - 34ms/step\n",
      "Epoch 231/500\n",
      "2/2 - 0s - loss: 0.9259 - accuracy: 0.6577 - val_loss: 1.1712 - val_accuracy: 0.5509 - 70ms/epoch - 35ms/step\n",
      "Epoch 232/500\n",
      "2/2 - 0s - loss: 0.9237 - accuracy: 0.6591 - val_loss: 1.1378 - val_accuracy: 0.5643 - 66ms/epoch - 33ms/step\n",
      "Epoch 233/500\n",
      "2/2 - 0s - loss: 0.9255 - accuracy: 0.6553 - val_loss: 1.1884 - val_accuracy: 0.5465 - 62ms/epoch - 31ms/step\n",
      "Epoch 234/500\n",
      "2/2 - 0s - loss: 0.9216 - accuracy: 0.6569 - val_loss: 1.1824 - val_accuracy: 0.5458 - 65ms/epoch - 33ms/step\n",
      "Epoch 235/500\n",
      "2/2 - 0s - loss: 0.9186 - accuracy: 0.6581 - val_loss: 1.1475 - val_accuracy: 0.5608 - 69ms/epoch - 34ms/step\n",
      "Epoch 236/500\n",
      "2/2 - 0s - loss: 0.9300 - accuracy: 0.6499 - val_loss: 1.1877 - val_accuracy: 0.5437 - 69ms/epoch - 35ms/step\n",
      "Epoch 237/500\n",
      "2/2 - 0s - loss: 0.9234 - accuracy: 0.6595 - val_loss: 1.1472 - val_accuracy: 0.5675 - 73ms/epoch - 36ms/step\n",
      "Epoch 238/500\n",
      "2/2 - 0s - loss: 0.9221 - accuracy: 0.6613 - val_loss: 1.1521 - val_accuracy: 0.5656 - 67ms/epoch - 33ms/step\n",
      "Epoch 239/500\n",
      "2/2 - 0s - loss: 0.9193 - accuracy: 0.6599 - val_loss: 1.1891 - val_accuracy: 0.5467 - 65ms/epoch - 32ms/step\n",
      "Epoch 240/500\n",
      "2/2 - 0s - loss: 0.9132 - accuracy: 0.6604 - val_loss: 1.1643 - val_accuracy: 0.5546 - 67ms/epoch - 34ms/step\n",
      "Epoch 241/500\n",
      "2/2 - 0s - loss: 0.9144 - accuracy: 0.6603 - val_loss: 1.1607 - val_accuracy: 0.5548 - 66ms/epoch - 33ms/step\n",
      "Epoch 242/500\n",
      "2/2 - 0s - loss: 0.9171 - accuracy: 0.6611 - val_loss: 1.1530 - val_accuracy: 0.5589 - 69ms/epoch - 34ms/step\n",
      "Epoch 243/500\n",
      "2/2 - 0s - loss: 0.9105 - accuracy: 0.6638 - val_loss: 1.1753 - val_accuracy: 0.5552 - 68ms/epoch - 34ms/step\n",
      "Epoch 244/500\n",
      "2/2 - 0s - loss: 0.9125 - accuracy: 0.6591 - val_loss: 1.1917 - val_accuracy: 0.5513 - 72ms/epoch - 36ms/step\n",
      "Epoch 245/500\n",
      "2/2 - 0s - loss: 0.9154 - accuracy: 0.6616 - val_loss: 1.1468 - val_accuracy: 0.5661 - 69ms/epoch - 34ms/step\n",
      "Epoch 246/500\n",
      "2/2 - 0s - loss: 0.9185 - accuracy: 0.6596 - val_loss: 1.1393 - val_accuracy: 0.5703 - 67ms/epoch - 34ms/step\n",
      "Epoch 247/500\n",
      "2/2 - 0s - loss: 0.9236 - accuracy: 0.6546 - val_loss: 1.1949 - val_accuracy: 0.5407 - 67ms/epoch - 33ms/step\n",
      "Epoch 248/500\n",
      "2/2 - 0s - loss: 0.9190 - accuracy: 0.6621 - val_loss: 1.1905 - val_accuracy: 0.5458 - 66ms/epoch - 33ms/step\n",
      "Epoch 249/500\n",
      "2/2 - 0s - loss: 0.9109 - accuracy: 0.6596 - val_loss: 1.1739 - val_accuracy: 0.5610 - 65ms/epoch - 32ms/step\n",
      "Epoch 250/500\n",
      "2/2 - 0s - loss: 0.9272 - accuracy: 0.6504 - val_loss: 1.2468 - val_accuracy: 0.5294 - 67ms/epoch - 34ms/step\n",
      "Epoch 251/500\n",
      "2/2 - 0s - loss: 0.9542 - accuracy: 0.6432 - val_loss: 1.1179 - val_accuracy: 0.5828 - 64ms/epoch - 32ms/step\n",
      "Epoch 252/500\n",
      "2/2 - 0s - loss: 0.9321 - accuracy: 0.6464 - val_loss: 1.1417 - val_accuracy: 0.5654 - 66ms/epoch - 33ms/step\n",
      "Epoch 253/500\n",
      "2/2 - 0s - loss: 0.9097 - accuracy: 0.6661 - val_loss: 1.2639 - val_accuracy: 0.5044 - 69ms/epoch - 34ms/step\n",
      "Epoch 254/500\n",
      "2/2 - 0s - loss: 0.9410 - accuracy: 0.6395 - val_loss: 1.1379 - val_accuracy: 0.5737 - 67ms/epoch - 34ms/step\n",
      "Epoch 255/500\n",
      "2/2 - 0s - loss: 0.9520 - accuracy: 0.6337 - val_loss: 1.1625 - val_accuracy: 0.5622 - 70ms/epoch - 35ms/step\n",
      "Epoch 256/500\n",
      "2/2 - 0s - loss: 0.9231 - accuracy: 0.6581 - val_loss: 1.1905 - val_accuracy: 0.5492 - 70ms/epoch - 35ms/step\n",
      "Epoch 257/500\n",
      "2/2 - 0s - loss: 0.9275 - accuracy: 0.6570 - val_loss: 1.1384 - val_accuracy: 0.5721 - 68ms/epoch - 34ms/step\n",
      "Epoch 258/500\n",
      "2/2 - 0s - loss: 0.9327 - accuracy: 0.6495 - val_loss: 1.2029 - val_accuracy: 0.5335 - 69ms/epoch - 35ms/step\n",
      "Epoch 259/500\n",
      "2/2 - 0s - loss: 0.9167 - accuracy: 0.6632 - val_loss: 1.1522 - val_accuracy: 0.5587 - 72ms/epoch - 36ms/step\n",
      "Epoch 260/500\n",
      "2/2 - 0s - loss: 0.9198 - accuracy: 0.6543 - val_loss: 1.1868 - val_accuracy: 0.5485 - 71ms/epoch - 36ms/step\n",
      "Epoch 261/500\n",
      "2/2 - 0s - loss: 0.9117 - accuracy: 0.6637 - val_loss: 1.2042 - val_accuracy: 0.5502 - 70ms/epoch - 35ms/step\n",
      "Epoch 262/500\n",
      "2/2 - 0s - loss: 0.9105 - accuracy: 0.6638 - val_loss: 1.1368 - val_accuracy: 0.5781 - 71ms/epoch - 36ms/step\n",
      "Epoch 263/500\n",
      "2/2 - 0s - loss: 0.9326 - accuracy: 0.6410 - val_loss: 1.1656 - val_accuracy: 0.5550 - 70ms/epoch - 35ms/step\n",
      "Epoch 264/500\n",
      "2/2 - 0s - loss: 0.9044 - accuracy: 0.6652 - val_loss: 1.1711 - val_accuracy: 0.5555 - 67ms/epoch - 33ms/step\n",
      "Epoch 265/500\n",
      "2/2 - 0s - loss: 0.9139 - accuracy: 0.6614 - val_loss: 1.1475 - val_accuracy: 0.5640 - 67ms/epoch - 33ms/step\n",
      "Epoch 266/500\n",
      "2/2 - 0s - loss: 0.9032 - accuracy: 0.6639 - val_loss: 1.1930 - val_accuracy: 0.5460 - 67ms/epoch - 34ms/step\n",
      "Epoch 267/500\n",
      "2/2 - 0s - loss: 0.9088 - accuracy: 0.6658 - val_loss: 1.1304 - val_accuracy: 0.5784 - 65ms/epoch - 33ms/step\n",
      "Epoch 268/500\n",
      "2/2 - 0s - loss: 0.9176 - accuracy: 0.6509 - val_loss: 1.1707 - val_accuracy: 0.5550 - 63ms/epoch - 31ms/step\n",
      "Epoch 269/500\n",
      "2/2 - 0s - loss: 0.9187 - accuracy: 0.6594 - val_loss: 1.1618 - val_accuracy: 0.5571 - 66ms/epoch - 33ms/step\n",
      "Epoch 270/500\n",
      "2/2 - 0s - loss: 0.9033 - accuracy: 0.6620 - val_loss: 1.1419 - val_accuracy: 0.5714 - 69ms/epoch - 34ms/step\n",
      "Epoch 271/500\n",
      "2/2 - 0s - loss: 0.9177 - accuracy: 0.6543 - val_loss: 1.2342 - val_accuracy: 0.5243 - 75ms/epoch - 37ms/step\n",
      "Epoch 272/500\n",
      "2/2 - 0s - loss: 0.9308 - accuracy: 0.6493 - val_loss: 1.1576 - val_accuracy: 0.5576 - 71ms/epoch - 35ms/step\n",
      "Epoch 273/500\n",
      "2/2 - 0s - loss: 0.9116 - accuracy: 0.6560 - val_loss: 1.1463 - val_accuracy: 0.5696 - 72ms/epoch - 36ms/step\n",
      "Epoch 274/500\n",
      "2/2 - 0s - loss: 0.9091 - accuracy: 0.6588 - val_loss: 1.1912 - val_accuracy: 0.5534 - 68ms/epoch - 34ms/step\n",
      "Epoch 275/500\n",
      "2/2 - 0s - loss: 0.9165 - accuracy: 0.6595 - val_loss: 1.1231 - val_accuracy: 0.5779 - 68ms/epoch - 34ms/step\n",
      "Epoch 276/500\n",
      "2/2 - 0s - loss: 0.9071 - accuracy: 0.6572 - val_loss: 1.1507 - val_accuracy: 0.5603 - 71ms/epoch - 35ms/step\n",
      "Epoch 277/500\n",
      "2/2 - 0s - loss: 0.8989 - accuracy: 0.6635 - val_loss: 1.2103 - val_accuracy: 0.5361 - 68ms/epoch - 34ms/step\n",
      "Epoch 278/500\n",
      "2/2 - 0s - loss: 0.9077 - accuracy: 0.6623 - val_loss: 1.1480 - val_accuracy: 0.5620 - 73ms/epoch - 37ms/step\n",
      "Epoch 279/500\n",
      "2/2 - 0s - loss: 0.8918 - accuracy: 0.6696 - val_loss: 1.1590 - val_accuracy: 0.5587 - 70ms/epoch - 35ms/step\n",
      "Epoch 280/500\n",
      "2/2 - 0s - loss: 0.8951 - accuracy: 0.6707 - val_loss: 1.1549 - val_accuracy: 0.5608 - 70ms/epoch - 35ms/step\n",
      "Epoch 281/500\n",
      "2/2 - 0s - loss: 0.8944 - accuracy: 0.6656 - val_loss: 1.1865 - val_accuracy: 0.5444 - 67ms/epoch - 33ms/step\n",
      "Epoch 282/500\n",
      "2/2 - 0s - loss: 0.8979 - accuracy: 0.6637 - val_loss: 1.1811 - val_accuracy: 0.5492 - 65ms/epoch - 32ms/step\n",
      "Epoch 283/500\n",
      "2/2 - 0s - loss: 0.8948 - accuracy: 0.6699 - val_loss: 1.1320 - val_accuracy: 0.5758 - 66ms/epoch - 33ms/step\n",
      "Epoch 284/500\n",
      "2/2 - 0s - loss: 0.9025 - accuracy: 0.6608 - val_loss: 1.1681 - val_accuracy: 0.5543 - 66ms/epoch - 33ms/step\n",
      "Epoch 285/500\n",
      "2/2 - 0s - loss: 0.8935 - accuracy: 0.6680 - val_loss: 1.1681 - val_accuracy: 0.5546 - 70ms/epoch - 35ms/step\n",
      "Epoch 286/500\n",
      "2/2 - 0s - loss: 0.8927 - accuracy: 0.6657 - val_loss: 1.1484 - val_accuracy: 0.5652 - 65ms/epoch - 33ms/step\n",
      "Epoch 287/500\n",
      "2/2 - 0s - loss: 0.8958 - accuracy: 0.6633 - val_loss: 1.1783 - val_accuracy: 0.5529 - 69ms/epoch - 34ms/step\n",
      "Epoch 288/500\n",
      "2/2 - 0s - loss: 0.8938 - accuracy: 0.6669 - val_loss: 1.1281 - val_accuracy: 0.5756 - 67ms/epoch - 34ms/step\n",
      "Epoch 289/500\n",
      "2/2 - 0s - loss: 0.8998 - accuracy: 0.6606 - val_loss: 1.1519 - val_accuracy: 0.5631 - 69ms/epoch - 34ms/step\n",
      "Epoch 290/500\n",
      "2/2 - 0s - loss: 0.8918 - accuracy: 0.6695 - val_loss: 1.1854 - val_accuracy: 0.5502 - 68ms/epoch - 34ms/step\n",
      "Epoch 291/500\n",
      "2/2 - 0s - loss: 0.8971 - accuracy: 0.6673 - val_loss: 1.1376 - val_accuracy: 0.5693 - 67ms/epoch - 33ms/step\n",
      "Epoch 292/500\n",
      "2/2 - 0s - loss: 0.8998 - accuracy: 0.6650 - val_loss: 1.1683 - val_accuracy: 0.5562 - 65ms/epoch - 32ms/step\n",
      "Epoch 293/500\n",
      "2/2 - 0s - loss: 0.8912 - accuracy: 0.6680 - val_loss: 1.1486 - val_accuracy: 0.5652 - 66ms/epoch - 33ms/step\n",
      "Epoch 294/500\n",
      "2/2 - 0s - loss: 0.8863 - accuracy: 0.6710 - val_loss: 1.1470 - val_accuracy: 0.5673 - 67ms/epoch - 33ms/step\n",
      "Epoch 295/500\n",
      "2/2 - 0s - loss: 0.8861 - accuracy: 0.6701 - val_loss: 1.1598 - val_accuracy: 0.5640 - 69ms/epoch - 34ms/step\n",
      "Epoch 296/500\n",
      "2/2 - 0s - loss: 0.8855 - accuracy: 0.6708 - val_loss: 1.1734 - val_accuracy: 0.5557 - 70ms/epoch - 35ms/step\n",
      "Epoch 297/500\n",
      "2/2 - 0s - loss: 0.8861 - accuracy: 0.6689 - val_loss: 1.1502 - val_accuracy: 0.5661 - 68ms/epoch - 34ms/step\n",
      "Epoch 298/500\n",
      "2/2 - 0s - loss: 0.8909 - accuracy: 0.6706 - val_loss: 1.1369 - val_accuracy: 0.5735 - 66ms/epoch - 33ms/step\n",
      "Epoch 299/500\n",
      "2/2 - 0s - loss: 0.8864 - accuracy: 0.6706 - val_loss: 1.1826 - val_accuracy: 0.5534 - 69ms/epoch - 34ms/step\n",
      "Epoch 300/500\n",
      "2/2 - 0s - loss: 0.8895 - accuracy: 0.6683 - val_loss: 1.1453 - val_accuracy: 0.5707 - 68ms/epoch - 34ms/step\n",
      "Epoch 301/500\n",
      "2/2 - 0s - loss: 0.8842 - accuracy: 0.6690 - val_loss: 1.1319 - val_accuracy: 0.5798 - 65ms/epoch - 33ms/step\n",
      "Epoch 302/500\n",
      "2/2 - 0s - loss: 0.8868 - accuracy: 0.6690 - val_loss: 1.1709 - val_accuracy: 0.5622 - 66ms/epoch - 33ms/step\n",
      "Epoch 303/500\n",
      "2/2 - 0s - loss: 0.8864 - accuracy: 0.6733 - val_loss: 1.1431 - val_accuracy: 0.5691 - 66ms/epoch - 33ms/step\n",
      "Epoch 304/500\n",
      "2/2 - 0s - loss: 0.8849 - accuracy: 0.6695 - val_loss: 1.1802 - val_accuracy: 0.5525 - 67ms/epoch - 34ms/step\n",
      "Epoch 305/500\n",
      "2/2 - 0s - loss: 0.8832 - accuracy: 0.6736 - val_loss: 1.1807 - val_accuracy: 0.5552 - 72ms/epoch - 36ms/step\n",
      "Epoch 306/500\n",
      "2/2 - 0s - loss: 0.8836 - accuracy: 0.6723 - val_loss: 1.1288 - val_accuracy: 0.5800 - 68ms/epoch - 34ms/step\n",
      "Epoch 307/500\n",
      "2/2 - 0s - loss: 0.8895 - accuracy: 0.6654 - val_loss: 1.1578 - val_accuracy: 0.5682 - 64ms/epoch - 32ms/step\n",
      "Epoch 308/500\n",
      "2/2 - 0s - loss: 0.8963 - accuracy: 0.6668 - val_loss: 1.1403 - val_accuracy: 0.5758 - 65ms/epoch - 32ms/step\n",
      "Epoch 309/500\n",
      "2/2 - 0s - loss: 0.9073 - accuracy: 0.6554 - val_loss: 1.1716 - val_accuracy: 0.5548 - 64ms/epoch - 32ms/step\n",
      "Epoch 310/500\n",
      "2/2 - 0s - loss: 0.8923 - accuracy: 0.6676 - val_loss: 1.2019 - val_accuracy: 0.5458 - 64ms/epoch - 32ms/step\n",
      "Epoch 311/500\n",
      "2/2 - 0s - loss: 0.8899 - accuracy: 0.6668 - val_loss: 1.1391 - val_accuracy: 0.5807 - 68ms/epoch - 34ms/step\n",
      "Epoch 312/500\n",
      "2/2 - 0s - loss: 0.9067 - accuracy: 0.6565 - val_loss: 1.1951 - val_accuracy: 0.5488 - 68ms/epoch - 34ms/step\n",
      "Epoch 313/500\n",
      "2/2 - 0s - loss: 0.8865 - accuracy: 0.6696 - val_loss: 1.1757 - val_accuracy: 0.5578 - 69ms/epoch - 34ms/step\n",
      "Epoch 314/500\n",
      "2/2 - 0s - loss: 0.8800 - accuracy: 0.6720 - val_loss: 1.1556 - val_accuracy: 0.5631 - 71ms/epoch - 36ms/step\n",
      "Epoch 315/500\n",
      "2/2 - 0s - loss: 0.8772 - accuracy: 0.6736 - val_loss: 1.1448 - val_accuracy: 0.5698 - 66ms/epoch - 33ms/step\n",
      "Epoch 316/500\n",
      "2/2 - 0s - loss: 0.8820 - accuracy: 0.6688 - val_loss: 1.1600 - val_accuracy: 0.5629 - 67ms/epoch - 33ms/step\n",
      "Epoch 317/500\n",
      "2/2 - 0s - loss: 0.8778 - accuracy: 0.6752 - val_loss: 1.1593 - val_accuracy: 0.5645 - 66ms/epoch - 33ms/step\n",
      "Epoch 318/500\n",
      "2/2 - 0s - loss: 0.8733 - accuracy: 0.6790 - val_loss: 1.1332 - val_accuracy: 0.5749 - 65ms/epoch - 33ms/step\n",
      "Epoch 319/500\n",
      "2/2 - 0s - loss: 0.8826 - accuracy: 0.6695 - val_loss: 1.1771 - val_accuracy: 0.5529 - 64ms/epoch - 32ms/step\n",
      "Epoch 320/500\n",
      "2/2 - 0s - loss: 0.8776 - accuracy: 0.6753 - val_loss: 1.1516 - val_accuracy: 0.5670 - 66ms/epoch - 33ms/step\n",
      "Epoch 321/500\n",
      "2/2 - 0s - loss: 0.8705 - accuracy: 0.6752 - val_loss: 1.1451 - val_accuracy: 0.5767 - 66ms/epoch - 33ms/step\n",
      "Epoch 322/500\n",
      "2/2 - 0s - loss: 0.8846 - accuracy: 0.6665 - val_loss: 1.1668 - val_accuracy: 0.5656 - 66ms/epoch - 33ms/step\n",
      "Epoch 323/500\n",
      "2/2 - 0s - loss: 0.8738 - accuracy: 0.6748 - val_loss: 1.1614 - val_accuracy: 0.5617 - 71ms/epoch - 35ms/step\n",
      "Epoch 324/500\n",
      "2/2 - 0s - loss: 0.8762 - accuracy: 0.6731 - val_loss: 1.1567 - val_accuracy: 0.5682 - 70ms/epoch - 35ms/step\n",
      "Epoch 325/500\n",
      "2/2 - 0s - loss: 0.8756 - accuracy: 0.6736 - val_loss: 1.1735 - val_accuracy: 0.5666 - 68ms/epoch - 34ms/step\n",
      "Epoch 326/500\n",
      "2/2 - 0s - loss: 0.8832 - accuracy: 0.6752 - val_loss: 1.1613 - val_accuracy: 0.5650 - 71ms/epoch - 35ms/step\n",
      "Epoch 327/500\n",
      "2/2 - 0s - loss: 0.8742 - accuracy: 0.6760 - val_loss: 1.1856 - val_accuracy: 0.5532 - 66ms/epoch - 33ms/step\n",
      "Epoch 328/500\n",
      "2/2 - 0s - loss: 0.8802 - accuracy: 0.6702 - val_loss: 1.1665 - val_accuracy: 0.5629 - 70ms/epoch - 35ms/step\n",
      "Epoch 329/500\n",
      "2/2 - 0s - loss: 0.8727 - accuracy: 0.6727 - val_loss: 1.1336 - val_accuracy: 0.5747 - 68ms/epoch - 34ms/step\n",
      "Epoch 330/500\n",
      "2/2 - 0s - loss: 0.8751 - accuracy: 0.6721 - val_loss: 1.1568 - val_accuracy: 0.5684 - 71ms/epoch - 36ms/step\n",
      "Epoch 331/500\n",
      "2/2 - 0s - loss: 0.8655 - accuracy: 0.6774 - val_loss: 1.1805 - val_accuracy: 0.5594 - 66ms/epoch - 33ms/step\n",
      "Epoch 332/500\n",
      "2/2 - 0s - loss: 0.8733 - accuracy: 0.6737 - val_loss: 1.1913 - val_accuracy: 0.5564 - 67ms/epoch - 34ms/step\n",
      "Epoch 333/500\n",
      "2/2 - 0s - loss: 0.8729 - accuracy: 0.6767 - val_loss: 1.1448 - val_accuracy: 0.5740 - 64ms/epoch - 32ms/step\n",
      "Epoch 334/500\n",
      "2/2 - 0s - loss: 0.8711 - accuracy: 0.6747 - val_loss: 1.1638 - val_accuracy: 0.5661 - 64ms/epoch - 32ms/step\n",
      "Epoch 335/500\n",
      "2/2 - 0s - loss: 0.8681 - accuracy: 0.6789 - val_loss: 1.1637 - val_accuracy: 0.5684 - 63ms/epoch - 31ms/step\n",
      "Epoch 336/500\n",
      "2/2 - 0s - loss: 0.8711 - accuracy: 0.6763 - val_loss: 1.1512 - val_accuracy: 0.5652 - 65ms/epoch - 32ms/step\n",
      "Epoch 337/500\n",
      "2/2 - 0s - loss: 0.8691 - accuracy: 0.6753 - val_loss: 1.1658 - val_accuracy: 0.5587 - 65ms/epoch - 33ms/step\n",
      "Epoch 338/500\n",
      "2/2 - 0s - loss: 0.8686 - accuracy: 0.6753 - val_loss: 1.1466 - val_accuracy: 0.5726 - 65ms/epoch - 33ms/step\n",
      "Epoch 339/500\n",
      "2/2 - 0s - loss: 0.8662 - accuracy: 0.6729 - val_loss: 1.1725 - val_accuracy: 0.5691 - 71ms/epoch - 35ms/step\n",
      "Epoch 340/500\n",
      "2/2 - 0s - loss: 0.8701 - accuracy: 0.6760 - val_loss: 1.1405 - val_accuracy: 0.5807 - 68ms/epoch - 34ms/step\n",
      "Epoch 341/500\n",
      "2/2 - 0s - loss: 0.8733 - accuracy: 0.6696 - val_loss: 1.1944 - val_accuracy: 0.5534 - 70ms/epoch - 35ms/step\n",
      "Epoch 342/500\n",
      "2/2 - 0s - loss: 0.8781 - accuracy: 0.6720 - val_loss: 1.1648 - val_accuracy: 0.5684 - 67ms/epoch - 33ms/step\n",
      "Epoch 343/500\n",
      "2/2 - 0s - loss: 0.8730 - accuracy: 0.6719 - val_loss: 1.1375 - val_accuracy: 0.5848 - 68ms/epoch - 34ms/step\n",
      "Epoch 344/500\n",
      "2/2 - 0s - loss: 0.8814 - accuracy: 0.6720 - val_loss: 1.1763 - val_accuracy: 0.5638 - 67ms/epoch - 34ms/step\n",
      "Epoch 345/500\n",
      "2/2 - 0s - loss: 0.8714 - accuracy: 0.6747 - val_loss: 1.1679 - val_accuracy: 0.5691 - 65ms/epoch - 33ms/step\n",
      "Epoch 346/500\n",
      "2/2 - 0s - loss: 0.8707 - accuracy: 0.6733 - val_loss: 1.1826 - val_accuracy: 0.5589 - 69ms/epoch - 35ms/step\n",
      "Epoch 347/500\n",
      "2/2 - 0s - loss: 0.8632 - accuracy: 0.6807 - val_loss: 1.1365 - val_accuracy: 0.5804 - 69ms/epoch - 34ms/step\n",
      "Epoch 348/500\n",
      "2/2 - 0s - loss: 0.8742 - accuracy: 0.6727 - val_loss: 1.1902 - val_accuracy: 0.5536 - 73ms/epoch - 37ms/step\n",
      "Epoch 349/500\n",
      "2/2 - 0s - loss: 0.8712 - accuracy: 0.6772 - val_loss: 1.1664 - val_accuracy: 0.5633 - 72ms/epoch - 36ms/step\n",
      "Epoch 350/500\n",
      "2/2 - 0s - loss: 0.8695 - accuracy: 0.6741 - val_loss: 1.1609 - val_accuracy: 0.5700 - 67ms/epoch - 33ms/step\n",
      "Epoch 351/500\n",
      "2/2 - 0s - loss: 0.8649 - accuracy: 0.6775 - val_loss: 1.2123 - val_accuracy: 0.5437 - 66ms/epoch - 33ms/step\n",
      "Epoch 352/500\n",
      "2/2 - 0s - loss: 0.8755 - accuracy: 0.6760 - val_loss: 1.1350 - val_accuracy: 0.5807 - 69ms/epoch - 34ms/step\n",
      "Epoch 353/500\n",
      "2/2 - 0s - loss: 0.8698 - accuracy: 0.6710 - val_loss: 1.1695 - val_accuracy: 0.5622 - 66ms/epoch - 33ms/step\n",
      "Epoch 354/500\n",
      "2/2 - 0s - loss: 0.8642 - accuracy: 0.6794 - val_loss: 1.1533 - val_accuracy: 0.5705 - 65ms/epoch - 32ms/step\n",
      "Epoch 355/500\n",
      "2/2 - 0s - loss: 0.8716 - accuracy: 0.6735 - val_loss: 1.1634 - val_accuracy: 0.5696 - 64ms/epoch - 32ms/step\n",
      "Epoch 356/500\n",
      "2/2 - 0s - loss: 0.8640 - accuracy: 0.6758 - val_loss: 1.1823 - val_accuracy: 0.5613 - 67ms/epoch - 34ms/step\n",
      "Epoch 357/500\n",
      "2/2 - 0s - loss: 0.8595 - accuracy: 0.6795 - val_loss: 1.1229 - val_accuracy: 0.5871 - 67ms/epoch - 34ms/step\n",
      "Epoch 358/500\n",
      "2/2 - 0s - loss: 0.8697 - accuracy: 0.6737 - val_loss: 1.1888 - val_accuracy: 0.5527 - 70ms/epoch - 35ms/step\n",
      "Epoch 359/500\n",
      "2/2 - 0s - loss: 0.8673 - accuracy: 0.6785 - val_loss: 1.1549 - val_accuracy: 0.5710 - 71ms/epoch - 35ms/step\n",
      "Epoch 360/500\n",
      "2/2 - 0s - loss: 0.8611 - accuracy: 0.6801 - val_loss: 1.1402 - val_accuracy: 0.5802 - 67ms/epoch - 33ms/step\n",
      "Epoch 361/500\n",
      "2/2 - 0s - loss: 0.8610 - accuracy: 0.6774 - val_loss: 1.1685 - val_accuracy: 0.5691 - 64ms/epoch - 32ms/step\n",
      "Epoch 362/500\n",
      "2/2 - 0s - loss: 0.8600 - accuracy: 0.6821 - val_loss: 1.1416 - val_accuracy: 0.5742 - 65ms/epoch - 32ms/step\n",
      "Epoch 363/500\n",
      "2/2 - 0s - loss: 0.8564 - accuracy: 0.6804 - val_loss: 1.1553 - val_accuracy: 0.5717 - 73ms/epoch - 37ms/step\n",
      "Epoch 364/500\n",
      "2/2 - 0s - loss: 0.8590 - accuracy: 0.6774 - val_loss: 1.1548 - val_accuracy: 0.5749 - 72ms/epoch - 36ms/step\n",
      "Epoch 365/500\n",
      "2/2 - 0s - loss: 0.8552 - accuracy: 0.6783 - val_loss: 1.1599 - val_accuracy: 0.5758 - 69ms/epoch - 34ms/step\n",
      "Epoch 366/500\n",
      "2/2 - 0s - loss: 0.8578 - accuracy: 0.6813 - val_loss: 1.1691 - val_accuracy: 0.5693 - 67ms/epoch - 33ms/step\n",
      "Epoch 367/500\n",
      "2/2 - 0s - loss: 0.8611 - accuracy: 0.6782 - val_loss: 1.1778 - val_accuracy: 0.5624 - 67ms/epoch - 34ms/step\n",
      "Epoch 368/500\n",
      "2/2 - 0s - loss: 0.8570 - accuracy: 0.6805 - val_loss: 1.1520 - val_accuracy: 0.5761 - 66ms/epoch - 33ms/step\n",
      "Epoch 369/500\n",
      "2/2 - 0s - loss: 0.8548 - accuracy: 0.6836 - val_loss: 1.1317 - val_accuracy: 0.5837 - 65ms/epoch - 32ms/step\n",
      "Epoch 370/500\n",
      "2/2 - 0s - loss: 0.8586 - accuracy: 0.6780 - val_loss: 1.1733 - val_accuracy: 0.5636 - 66ms/epoch - 33ms/step\n",
      "Epoch 371/500\n",
      "2/2 - 0s - loss: 0.8517 - accuracy: 0.6847 - val_loss: 1.2019 - val_accuracy: 0.5485 - 68ms/epoch - 34ms/step\n",
      "Epoch 372/500\n",
      "2/2 - 0s - loss: 0.8662 - accuracy: 0.6764 - val_loss: 1.1498 - val_accuracy: 0.5726 - 66ms/epoch - 33ms/step\n",
      "Epoch 373/500\n",
      "2/2 - 0s - loss: 0.8695 - accuracy: 0.6752 - val_loss: 1.1287 - val_accuracy: 0.5837 - 67ms/epoch - 33ms/step\n",
      "Epoch 374/500\n",
      "2/2 - 0s - loss: 0.8669 - accuracy: 0.6733 - val_loss: 1.2181 - val_accuracy: 0.5481 - 70ms/epoch - 35ms/step\n",
      "Epoch 375/500\n",
      "2/2 - 0s - loss: 0.8706 - accuracy: 0.6729 - val_loss: 1.1508 - val_accuracy: 0.5749 - 70ms/epoch - 35ms/step\n",
      "Epoch 376/500\n",
      "2/2 - 0s - loss: 0.8556 - accuracy: 0.6794 - val_loss: 1.1484 - val_accuracy: 0.5726 - 69ms/epoch - 34ms/step\n",
      "Epoch 377/500\n",
      "2/2 - 0s - loss: 0.8581 - accuracy: 0.6815 - val_loss: 1.1668 - val_accuracy: 0.5650 - 64ms/epoch - 32ms/step\n",
      "Epoch 378/500\n",
      "2/2 - 0s - loss: 0.8505 - accuracy: 0.6845 - val_loss: 1.1623 - val_accuracy: 0.5717 - 64ms/epoch - 32ms/step\n",
      "Epoch 379/500\n",
      "2/2 - 0s - loss: 0.8616 - accuracy: 0.6772 - val_loss: 1.1891 - val_accuracy: 0.5620 - 66ms/epoch - 33ms/step\n",
      "Epoch 380/500\n",
      "2/2 - 0s - loss: 0.8624 - accuracy: 0.6751 - val_loss: 1.1395 - val_accuracy: 0.5821 - 67ms/epoch - 33ms/step\n",
      "Epoch 381/500\n",
      "2/2 - 0s - loss: 0.8514 - accuracy: 0.6829 - val_loss: 1.1685 - val_accuracy: 0.5663 - 68ms/epoch - 34ms/step\n",
      "Epoch 382/500\n",
      "2/2 - 0s - loss: 0.8527 - accuracy: 0.6808 - val_loss: 1.1567 - val_accuracy: 0.5714 - 64ms/epoch - 32ms/step\n",
      "Epoch 383/500\n",
      "2/2 - 0s - loss: 0.8528 - accuracy: 0.6818 - val_loss: 1.1512 - val_accuracy: 0.5772 - 66ms/epoch - 33ms/step\n",
      "Epoch 384/500\n",
      "2/2 - 0s - loss: 0.8540 - accuracy: 0.6794 - val_loss: 1.1615 - val_accuracy: 0.5726 - 66ms/epoch - 33ms/step\n",
      "Epoch 385/500\n",
      "2/2 - 0s - loss: 0.8537 - accuracy: 0.6826 - val_loss: 1.1675 - val_accuracy: 0.5640 - 66ms/epoch - 33ms/step\n",
      "Epoch 386/500\n",
      "2/2 - 0s - loss: 0.8497 - accuracy: 0.6855 - val_loss: 1.1604 - val_accuracy: 0.5707 - 68ms/epoch - 34ms/step\n",
      "Epoch 387/500\n",
      "2/2 - 0s - loss: 0.8449 - accuracy: 0.6835 - val_loss: 1.1468 - val_accuracy: 0.5770 - 65ms/epoch - 33ms/step\n",
      "Epoch 388/500\n",
      "2/2 - 0s - loss: 0.8578 - accuracy: 0.6762 - val_loss: 1.1666 - val_accuracy: 0.5710 - 67ms/epoch - 33ms/step\n",
      "Epoch 389/500\n",
      "2/2 - 0s - loss: 0.8554 - accuracy: 0.6807 - val_loss: 1.1514 - val_accuracy: 0.5807 - 65ms/epoch - 32ms/step\n",
      "Epoch 390/500\n",
      "2/2 - 0s - loss: 0.8477 - accuracy: 0.6855 - val_loss: 1.1827 - val_accuracy: 0.5596 - 65ms/epoch - 33ms/step\n",
      "Epoch 391/500\n",
      "2/2 - 0s - loss: 0.8498 - accuracy: 0.6824 - val_loss: 1.1683 - val_accuracy: 0.5735 - 69ms/epoch - 35ms/step\n",
      "Epoch 392/500\n",
      "2/2 - 0s - loss: 0.8478 - accuracy: 0.6881 - val_loss: 1.1468 - val_accuracy: 0.5846 - 67ms/epoch - 34ms/step\n",
      "Epoch 393/500\n",
      "2/2 - 0s - loss: 0.8549 - accuracy: 0.6828 - val_loss: 1.2035 - val_accuracy: 0.5506 - 69ms/epoch - 35ms/step\n",
      "Epoch 394/500\n",
      "2/2 - 0s - loss: 0.8603 - accuracy: 0.6774 - val_loss: 1.1533 - val_accuracy: 0.5754 - 64ms/epoch - 32ms/step\n",
      "Epoch 395/500\n",
      "2/2 - 0s - loss: 0.8519 - accuracy: 0.6781 - val_loss: 1.1405 - val_accuracy: 0.5828 - 62ms/epoch - 31ms/step\n",
      "Epoch 396/500\n",
      "2/2 - 0s - loss: 0.8444 - accuracy: 0.6845 - val_loss: 1.2149 - val_accuracy: 0.5479 - 62ms/epoch - 31ms/step\n",
      "Epoch 397/500\n",
      "2/2 - 0s - loss: 0.8641 - accuracy: 0.6743 - val_loss: 1.1548 - val_accuracy: 0.5719 - 67ms/epoch - 33ms/step\n",
      "Epoch 398/500\n",
      "2/2 - 0s - loss: 0.8499 - accuracy: 0.6824 - val_loss: 1.1971 - val_accuracy: 0.5492 - 65ms/epoch - 32ms/step\n",
      "Epoch 399/500\n",
      "2/2 - 0s - loss: 0.8513 - accuracy: 0.6824 - val_loss: 1.1397 - val_accuracy: 0.5821 - 69ms/epoch - 34ms/step\n",
      "Epoch 400/500\n",
      "2/2 - 0s - loss: 0.8436 - accuracy: 0.6840 - val_loss: 1.1793 - val_accuracy: 0.5647 - 68ms/epoch - 34ms/step\n",
      "Epoch 401/500\n",
      "2/2 - 0s - loss: 0.8490 - accuracy: 0.6855 - val_loss: 1.1436 - val_accuracy: 0.5818 - 62ms/epoch - 31ms/step\n",
      "Epoch 402/500\n",
      "2/2 - 0s - loss: 0.8595 - accuracy: 0.6763 - val_loss: 1.1781 - val_accuracy: 0.5647 - 64ms/epoch - 32ms/step\n",
      "Epoch 403/500\n",
      "2/2 - 0s - loss: 0.8507 - accuracy: 0.6830 - val_loss: 1.1556 - val_accuracy: 0.5807 - 66ms/epoch - 33ms/step\n",
      "Epoch 404/500\n",
      "2/2 - 0s - loss: 0.8569 - accuracy: 0.6788 - val_loss: 1.1393 - val_accuracy: 0.5851 - 62ms/epoch - 31ms/step\n",
      "Epoch 405/500\n",
      "2/2 - 0s - loss: 0.8514 - accuracy: 0.6799 - val_loss: 1.2431 - val_accuracy: 0.5305 - 64ms/epoch - 32ms/step\n",
      "Epoch 406/500\n",
      "2/2 - 0s - loss: 0.8577 - accuracy: 0.6782 - val_loss: 1.1405 - val_accuracy: 0.5784 - 65ms/epoch - 33ms/step\n",
      "Epoch 407/500\n",
      "2/2 - 0s - loss: 0.8561 - accuracy: 0.6788 - val_loss: 1.1514 - val_accuracy: 0.5761 - 82ms/epoch - 41ms/step\n",
      "Epoch 408/500\n",
      "2/2 - 0s - loss: 0.8435 - accuracy: 0.6876 - val_loss: 1.1936 - val_accuracy: 0.5668 - 68ms/epoch - 34ms/step\n",
      "Epoch 409/500\n",
      "2/2 - 0s - loss: 0.8540 - accuracy: 0.6787 - val_loss: 1.1827 - val_accuracy: 0.5700 - 66ms/epoch - 33ms/step\n",
      "Epoch 410/500\n",
      "2/2 - 0s - loss: 0.8568 - accuracy: 0.6799 - val_loss: 1.1974 - val_accuracy: 0.5580 - 65ms/epoch - 32ms/step\n",
      "Epoch 411/500\n",
      "2/2 - 0s - loss: 0.8558 - accuracy: 0.6805 - val_loss: 1.1515 - val_accuracy: 0.5818 - 64ms/epoch - 32ms/step\n",
      "Epoch 412/500\n",
      "2/2 - 0s - loss: 0.8415 - accuracy: 0.6859 - val_loss: 1.1905 - val_accuracy: 0.5603 - 63ms/epoch - 32ms/step\n",
      "Epoch 413/500\n",
      "2/2 - 0s - loss: 0.8554 - accuracy: 0.6818 - val_loss: 1.2004 - val_accuracy: 0.5569 - 62ms/epoch - 31ms/step\n",
      "Epoch 414/500\n",
      "2/2 - 0s - loss: 0.8652 - accuracy: 0.6784 - val_loss: 1.1543 - val_accuracy: 0.5774 - 63ms/epoch - 32ms/step\n",
      "Epoch 415/500\n",
      "2/2 - 0s - loss: 0.8423 - accuracy: 0.6888 - val_loss: 1.1593 - val_accuracy: 0.5800 - 71ms/epoch - 35ms/step\n",
      "Epoch 416/500\n",
      "2/2 - 0s - loss: 0.8505 - accuracy: 0.6861 - val_loss: 1.1425 - val_accuracy: 0.5828 - 69ms/epoch - 35ms/step\n",
      "Epoch 417/500\n",
      "2/2 - 0s - loss: 0.8471 - accuracy: 0.6818 - val_loss: 1.1974 - val_accuracy: 0.5578 - 67ms/epoch - 34ms/step\n",
      "Epoch 418/500\n",
      "2/2 - 0s - loss: 0.8395 - accuracy: 0.6872 - val_loss: 1.1359 - val_accuracy: 0.5804 - 66ms/epoch - 33ms/step\n",
      "Epoch 419/500\n",
      "2/2 - 0s - loss: 0.8402 - accuracy: 0.6836 - val_loss: 1.1755 - val_accuracy: 0.5620 - 65ms/epoch - 32ms/step\n",
      "Epoch 420/500\n",
      "2/2 - 0s - loss: 0.8424 - accuracy: 0.6875 - val_loss: 1.1508 - val_accuracy: 0.5793 - 63ms/epoch - 32ms/step\n",
      "Epoch 421/500\n",
      "2/2 - 0s - loss: 0.8327 - accuracy: 0.6882 - val_loss: 1.1589 - val_accuracy: 0.5795 - 67ms/epoch - 34ms/step\n",
      "Epoch 422/500\n",
      "2/2 - 0s - loss: 0.8314 - accuracy: 0.6898 - val_loss: 1.1930 - val_accuracy: 0.5636 - 64ms/epoch - 32ms/step\n",
      "Epoch 423/500\n",
      "2/2 - 0s - loss: 0.8355 - accuracy: 0.6893 - val_loss: 1.1470 - val_accuracy: 0.5865 - 62ms/epoch - 31ms/step\n",
      "Epoch 424/500\n",
      "2/2 - 0s - loss: 0.8371 - accuracy: 0.6856 - val_loss: 1.1617 - val_accuracy: 0.5795 - 62ms/epoch - 31ms/step\n",
      "Epoch 425/500\n",
      "2/2 - 0s - loss: 0.8324 - accuracy: 0.6901 - val_loss: 1.1621 - val_accuracy: 0.5781 - 65ms/epoch - 33ms/step\n",
      "Epoch 426/500\n",
      "2/2 - 0s - loss: 0.8312 - accuracy: 0.6899 - val_loss: 1.1754 - val_accuracy: 0.5728 - 66ms/epoch - 33ms/step\n",
      "Epoch 427/500\n",
      "2/2 - 0s - loss: 0.8290 - accuracy: 0.6905 - val_loss: 1.1497 - val_accuracy: 0.5867 - 63ms/epoch - 31ms/step\n",
      "Epoch 428/500\n",
      "2/2 - 0s - loss: 0.8303 - accuracy: 0.6888 - val_loss: 1.1568 - val_accuracy: 0.5895 - 61ms/epoch - 31ms/step\n",
      "Epoch 429/500\n",
      "2/2 - 0s - loss: 0.8373 - accuracy: 0.6878 - val_loss: 1.1765 - val_accuracy: 0.5698 - 63ms/epoch - 32ms/step\n",
      "Epoch 430/500\n",
      "2/2 - 0s - loss: 0.8293 - accuracy: 0.6877 - val_loss: 1.1726 - val_accuracy: 0.5726 - 63ms/epoch - 32ms/step\n",
      "Epoch 431/500\n",
      "2/2 - 0s - loss: 0.8439 - accuracy: 0.6838 - val_loss: 1.1857 - val_accuracy: 0.5654 - 65ms/epoch - 33ms/step\n",
      "Epoch 432/500\n",
      "2/2 - 0s - loss: 0.8432 - accuracy: 0.6877 - val_loss: 1.1338 - val_accuracy: 0.5904 - 64ms/epoch - 32ms/step\n",
      "Epoch 433/500\n",
      "2/2 - 0s - loss: 0.8552 - accuracy: 0.6755 - val_loss: 1.1893 - val_accuracy: 0.5659 - 71ms/epoch - 35ms/step\n",
      "Epoch 434/500\n",
      "2/2 - 0s - loss: 0.8372 - accuracy: 0.6895 - val_loss: 1.1713 - val_accuracy: 0.5710 - 73ms/epoch - 37ms/step\n",
      "Epoch 435/500\n",
      "2/2 - 0s - loss: 0.8284 - accuracy: 0.6926 - val_loss: 1.1412 - val_accuracy: 0.5830 - 72ms/epoch - 36ms/step\n",
      "Epoch 436/500\n",
      "2/2 - 0s - loss: 0.8359 - accuracy: 0.6877 - val_loss: 1.2075 - val_accuracy: 0.5504 - 66ms/epoch - 33ms/step\n",
      "Epoch 437/500\n",
      "2/2 - 0s - loss: 0.8481 - accuracy: 0.6811 - val_loss: 1.1480 - val_accuracy: 0.5846 - 64ms/epoch - 32ms/step\n",
      "Epoch 438/500\n",
      "2/2 - 0s - loss: 0.8460 - accuracy: 0.6817 - val_loss: 1.1972 - val_accuracy: 0.5620 - 64ms/epoch - 32ms/step\n",
      "Epoch 439/500\n",
      "2/2 - 0s - loss: 0.8316 - accuracy: 0.6882 - val_loss: 1.1641 - val_accuracy: 0.5724 - 63ms/epoch - 32ms/step\n",
      "Epoch 440/500\n",
      "2/2 - 0s - loss: 0.8277 - accuracy: 0.6921 - val_loss: 1.1506 - val_accuracy: 0.5798 - 62ms/epoch - 31ms/step\n",
      "Epoch 441/500\n",
      "2/2 - 0s - loss: 0.8236 - accuracy: 0.6930 - val_loss: 1.1886 - val_accuracy: 0.5650 - 63ms/epoch - 31ms/step\n",
      "Epoch 442/500\n",
      "2/2 - 0s - loss: 0.8270 - accuracy: 0.6905 - val_loss: 1.1462 - val_accuracy: 0.5865 - 63ms/epoch - 32ms/step\n",
      "Epoch 443/500\n",
      "2/2 - 0s - loss: 0.8270 - accuracy: 0.6912 - val_loss: 1.1537 - val_accuracy: 0.5767 - 64ms/epoch - 32ms/step\n",
      "Epoch 444/500\n",
      "2/2 - 0s - loss: 0.8228 - accuracy: 0.6946 - val_loss: 1.1784 - val_accuracy: 0.5654 - 64ms/epoch - 32ms/step\n",
      "Epoch 445/500\n",
      "2/2 - 0s - loss: 0.8250 - accuracy: 0.6925 - val_loss: 1.1525 - val_accuracy: 0.5733 - 67ms/epoch - 34ms/step\n",
      "Epoch 446/500\n",
      "2/2 - 0s - loss: 0.8275 - accuracy: 0.6888 - val_loss: 1.2045 - val_accuracy: 0.5559 - 65ms/epoch - 32ms/step\n",
      "Epoch 447/500\n",
      "2/2 - 0s - loss: 0.8370 - accuracy: 0.6886 - val_loss: 1.1414 - val_accuracy: 0.5851 - 65ms/epoch - 32ms/step\n",
      "Epoch 448/500\n",
      "2/2 - 0s - loss: 0.8296 - accuracy: 0.6869 - val_loss: 1.1793 - val_accuracy: 0.5650 - 63ms/epoch - 31ms/step\n",
      "Epoch 449/500\n",
      "2/2 - 0s - loss: 0.8317 - accuracy: 0.6867 - val_loss: 1.1623 - val_accuracy: 0.5754 - 64ms/epoch - 32ms/step\n",
      "Epoch 450/500\n",
      "2/2 - 0s - loss: 0.8283 - accuracy: 0.6917 - val_loss: 1.1322 - val_accuracy: 0.5881 - 64ms/epoch - 32ms/step\n",
      "Epoch 451/500\n",
      "2/2 - 0s - loss: 0.8306 - accuracy: 0.6894 - val_loss: 1.2198 - val_accuracy: 0.5564 - 68ms/epoch - 34ms/step\n",
      "Epoch 452/500\n",
      "2/2 - 0s - loss: 0.8562 - accuracy: 0.6833 - val_loss: 1.1429 - val_accuracy: 0.5839 - 66ms/epoch - 33ms/step\n",
      "Epoch 453/500\n",
      "2/2 - 0s - loss: 0.8289 - accuracy: 0.6910 - val_loss: 1.1808 - val_accuracy: 0.5670 - 68ms/epoch - 34ms/step\n",
      "Epoch 454/500\n",
      "2/2 - 0s - loss: 0.8236 - accuracy: 0.6967 - val_loss: 1.1382 - val_accuracy: 0.5853 - 66ms/epoch - 33ms/step\n",
      "Epoch 455/500\n",
      "2/2 - 0s - loss: 0.8257 - accuracy: 0.6887 - val_loss: 1.1568 - val_accuracy: 0.5818 - 63ms/epoch - 31ms/step\n",
      "Epoch 456/500\n",
      "2/2 - 0s - loss: 0.8227 - accuracy: 0.6924 - val_loss: 1.1536 - val_accuracy: 0.5807 - 65ms/epoch - 32ms/step\n",
      "Epoch 457/500\n",
      "2/2 - 0s - loss: 0.8224 - accuracy: 0.6896 - val_loss: 1.1633 - val_accuracy: 0.5749 - 63ms/epoch - 31ms/step\n",
      "Epoch 458/500\n",
      "2/2 - 0s - loss: 0.8282 - accuracy: 0.6884 - val_loss: 1.1464 - val_accuracy: 0.5839 - 65ms/epoch - 33ms/step\n",
      "Epoch 459/500\n",
      "2/2 - 0s - loss: 0.8340 - accuracy: 0.6855 - val_loss: 1.2249 - val_accuracy: 0.5546 - 72ms/epoch - 36ms/step\n",
      "Epoch 460/500\n",
      "2/2 - 0s - loss: 0.8566 - accuracy: 0.6794 - val_loss: 1.1435 - val_accuracy: 0.5902 - 65ms/epoch - 33ms/step\n",
      "Epoch 461/500\n",
      "2/2 - 0s - loss: 0.8379 - accuracy: 0.6826 - val_loss: 1.1605 - val_accuracy: 0.5802 - 73ms/epoch - 36ms/step\n",
      "Epoch 462/500\n",
      "2/2 - 0s - loss: 0.8350 - accuracy: 0.6881 - val_loss: 1.1751 - val_accuracy: 0.5724 - 67ms/epoch - 34ms/step\n",
      "Epoch 463/500\n",
      "2/2 - 0s - loss: 0.8279 - accuracy: 0.6925 - val_loss: 1.1486 - val_accuracy: 0.5837 - 67ms/epoch - 33ms/step\n",
      "Epoch 464/500\n",
      "2/2 - 0s - loss: 0.8354 - accuracy: 0.6853 - val_loss: 1.2490 - val_accuracy: 0.5405 - 66ms/epoch - 33ms/step\n",
      "Epoch 465/500\n",
      "2/2 - 0s - loss: 0.8555 - accuracy: 0.6768 - val_loss: 1.1258 - val_accuracy: 0.5943 - 67ms/epoch - 33ms/step\n",
      "Epoch 466/500\n",
      "2/2 - 0s - loss: 0.8530 - accuracy: 0.6743 - val_loss: 1.1484 - val_accuracy: 0.5761 - 64ms/epoch - 32ms/step\n",
      "Epoch 467/500\n",
      "2/2 - 0s - loss: 0.8258 - accuracy: 0.6901 - val_loss: 1.2016 - val_accuracy: 0.5515 - 64ms/epoch - 32ms/step\n",
      "Epoch 468/500\n",
      "2/2 - 0s - loss: 0.8294 - accuracy: 0.6912 - val_loss: 1.1301 - val_accuracy: 0.5839 - 65ms/epoch - 33ms/step\n",
      "Epoch 469/500\n",
      "2/2 - 0s - loss: 0.8377 - accuracy: 0.6847 - val_loss: 1.1776 - val_accuracy: 0.5714 - 64ms/epoch - 32ms/step\n",
      "Epoch 470/500\n",
      "2/2 - 0s - loss: 0.8296 - accuracy: 0.6932 - val_loss: 1.1459 - val_accuracy: 0.5869 - 68ms/epoch - 34ms/step\n",
      "Epoch 471/500\n",
      "2/2 - 0s - loss: 0.8252 - accuracy: 0.6892 - val_loss: 1.1851 - val_accuracy: 0.5677 - 65ms/epoch - 33ms/step\n",
      "Epoch 472/500\n",
      "2/2 - 0s - loss: 0.8224 - accuracy: 0.6976 - val_loss: 1.1929 - val_accuracy: 0.5640 - 64ms/epoch - 32ms/step\n",
      "Epoch 473/500\n",
      "2/2 - 0s - loss: 0.8159 - accuracy: 0.6969 - val_loss: 1.1359 - val_accuracy: 0.5828 - 63ms/epoch - 32ms/step\n",
      "Epoch 474/500\n",
      "2/2 - 0s - loss: 0.8415 - accuracy: 0.6808 - val_loss: 1.2023 - val_accuracy: 0.5585 - 61ms/epoch - 31ms/step\n",
      "Epoch 475/500\n",
      "2/2 - 0s - loss: 0.8249 - accuracy: 0.6937 - val_loss: 1.1464 - val_accuracy: 0.5828 - 65ms/epoch - 32ms/step\n",
      "Epoch 476/500\n",
      "2/2 - 0s - loss: 0.8158 - accuracy: 0.6935 - val_loss: 1.1499 - val_accuracy: 0.5869 - 62ms/epoch - 31ms/step\n",
      "Epoch 477/500\n",
      "2/2 - 0s - loss: 0.8131 - accuracy: 0.6951 - val_loss: 1.1861 - val_accuracy: 0.5654 - 62ms/epoch - 31ms/step\n",
      "Epoch 478/500\n",
      "2/2 - 0s - loss: 0.8186 - accuracy: 0.6968 - val_loss: 1.1433 - val_accuracy: 0.5869 - 65ms/epoch - 33ms/step\n",
      "Epoch 479/500\n",
      "2/2 - 0s - loss: 0.8164 - accuracy: 0.6949 - val_loss: 1.1926 - val_accuracy: 0.5689 - 64ms/epoch - 32ms/step\n",
      "Epoch 480/500\n",
      "2/2 - 0s - loss: 0.8216 - accuracy: 0.6955 - val_loss: 1.1577 - val_accuracy: 0.5834 - 68ms/epoch - 34ms/step\n",
      "Epoch 481/500\n",
      "2/2 - 0s - loss: 0.8110 - accuracy: 0.6966 - val_loss: 1.1598 - val_accuracy: 0.5772 - 72ms/epoch - 36ms/step\n",
      "Epoch 482/500\n",
      "2/2 - 0s - loss: 0.8164 - accuracy: 0.6958 - val_loss: 1.1538 - val_accuracy: 0.5795 - 65ms/epoch - 33ms/step\n",
      "Epoch 483/500\n",
      "2/2 - 0s - loss: 0.8130 - accuracy: 0.6951 - val_loss: 1.1822 - val_accuracy: 0.5682 - 64ms/epoch - 32ms/step\n",
      "Epoch 484/500\n",
      "2/2 - 0s - loss: 0.8131 - accuracy: 0.6964 - val_loss: 1.1836 - val_accuracy: 0.5661 - 62ms/epoch - 31ms/step\n",
      "Epoch 485/500\n",
      "2/2 - 0s - loss: 0.8100 - accuracy: 0.6969 - val_loss: 1.1509 - val_accuracy: 0.5823 - 62ms/epoch - 31ms/step\n",
      "Epoch 486/500\n",
      "2/2 - 0s - loss: 0.8192 - accuracy: 0.6929 - val_loss: 1.2010 - val_accuracy: 0.5566 - 65ms/epoch - 32ms/step\n",
      "Epoch 487/500\n",
      "2/2 - 0s - loss: 0.8164 - accuracy: 0.6947 - val_loss: 1.1560 - val_accuracy: 0.5841 - 64ms/epoch - 32ms/step\n",
      "Epoch 488/500\n",
      "2/2 - 0s - loss: 0.8218 - accuracy: 0.6920 - val_loss: 1.1742 - val_accuracy: 0.5804 - 66ms/epoch - 33ms/step\n",
      "Epoch 489/500\n",
      "2/2 - 0s - loss: 0.8109 - accuracy: 0.6976 - val_loss: 1.1980 - val_accuracy: 0.5698 - 66ms/epoch - 33ms/step\n",
      "Epoch 490/500\n",
      "2/2 - 0s - loss: 0.8154 - accuracy: 0.6977 - val_loss: 1.1532 - val_accuracy: 0.5853 - 66ms/epoch - 33ms/step\n",
      "Epoch 491/500\n",
      "2/2 - 0s - loss: 0.8163 - accuracy: 0.6917 - val_loss: 1.2071 - val_accuracy: 0.5640 - 63ms/epoch - 31ms/step\n",
      "Epoch 492/500\n",
      "2/2 - 0s - loss: 0.8198 - accuracy: 0.6925 - val_loss: 1.1565 - val_accuracy: 0.5821 - 64ms/epoch - 32ms/step\n",
      "Epoch 493/500\n",
      "2/2 - 0s - loss: 0.8446 - accuracy: 0.6811 - val_loss: 1.2333 - val_accuracy: 0.5492 - 67ms/epoch - 34ms/step\n",
      "Epoch 494/500\n",
      "2/2 - 0s - loss: 0.8386 - accuracy: 0.6848 - val_loss: 1.1502 - val_accuracy: 0.5966 - 63ms/epoch - 31ms/step\n",
      "Epoch 495/500\n",
      "2/2 - 0s - loss: 0.8490 - accuracy: 0.6780 - val_loss: 1.1539 - val_accuracy: 0.5837 - 61ms/epoch - 30ms/step\n",
      "Epoch 496/500\n",
      "2/2 - 0s - loss: 0.8117 - accuracy: 0.6975 - val_loss: 1.2279 - val_accuracy: 0.5416 - 64ms/epoch - 32ms/step\n",
      "Epoch 497/500\n",
      "2/2 - 0s - loss: 0.8242 - accuracy: 0.6894 - val_loss: 1.1462 - val_accuracy: 0.5811 - 65ms/epoch - 32ms/step\n",
      "Epoch 498/500\n",
      "2/2 - 0s - loss: 0.8213 - accuracy: 0.6930 - val_loss: 1.2537 - val_accuracy: 0.5398 - 67ms/epoch - 34ms/step\n",
      "Epoch 499/500\n",
      "2/2 - 0s - loss: 0.8445 - accuracy: 0.6819 - val_loss: 1.1502 - val_accuracy: 0.5888 - 65ms/epoch - 32ms/step\n",
      "Epoch 500/500\n",
      "2/2 - 0s - loss: 0.8615 - accuracy: 0.6724 - val_loss: 1.1867 - val_accuracy: 0.5795 - 68ms/epoch - 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1edc8e4a670>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP model with 60% test accuracy\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu',input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()\n",
    "optimizer=Adam(learning_rate = 0.001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer , metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=16, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6429 - accuracy: 0.4773\n",
      "Test Loss: 1.6429\n",
      "Test Accuracy: 47.73%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d43a44f6100dae1b05a8d23f3c47983f44dabb3f3c579f40f17dea46e3e9585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
